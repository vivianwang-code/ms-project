# Confidence Score Module
# Based on peak hour detection, sleep hour detection, and data completeness

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®ä¸­æ–‡å­—é«”
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

class ConfidenceScoreModule:

    def __init__(self):
        self.time_slots = 96  # 96å€‹æ™‚æ®µï¼Œæ¯15åˆ†é˜ä¸€å€‹ (24*4)
        self.time_outliers_data = {}
        self.data_completeness_score = {}
        self.peak_hours = []
        self.sleep_hours = []
        self.confidence_matrix = {}
        self.data_quality_report = {}
        
        # è¼‰å…¥æ‚¨æä¾›çš„time outliersçµ±è¨ˆæ•¸æ“š
        self._load_time_outliers_data()

    def _load_time_outliers_data(self):
        """è¼‰å…¥time outliersçµ±è¨ˆæ•¸æ“š"""
        print("==== Loading Time Outliers Data ====")
        
        # æ‚¨æä¾›çš„çµ±è¨ˆæ•¸æ“š
        raw_data = """
        00:00,21 00:15,21 00:30,21 00:45,21 01:00,23 01:15,23 01:30,21 01:45,22 02:00,27 02:15,31 02:30,30 02:45,36 
        03:00,36 03:15,35 03:30,33 03:45,37 04:00,36 04:15,36 04:30,37 04:45,36 05:00,37 05:15,36 05:30,38 05:45,34 
        06:00,36 06:15,38 06:30,37 06:45,38 07:00,40 07:15,39 07:30,37 07:45,40 08:00,37 08:15,40 08:30,39 08:45,39 
        09:00,38 09:15,39 09:30,37 09:45,38 10:00,36 10:15,36 10:30,35 10:45,33 11:00,38 11:15,37 11:30,36 11:45,36 
        12:00,36 12:15,37 12:30,37 12:45,36 13:00,36 13:15,35 13:30,39 13:45,41 14:00,43 14:15,42 14:30,44 14:45,45 
        15:00,44 15:15,45 15:30,43 15:45,40 16:00,40 16:15,38 16:30,38 16:45,37 17:00,37 17:15,36 17:30,28 17:45,23 
        18:00,24 18:15,21 18:30,20 18:45,20 19:00,19 19:15,20 19:30,18 19:45,18 20:00,18 20:15,18 20:30,18 20:45,21 
        21:00,22 21:15,21 21:30,21 21:45,21 22:00,22 22:15,22 22:30,23 22:45,22 23:00,21 23:15,21 23:30,21 23:45,21
        """
        
        # è§£ææ•¸æ“š
        entries = raw_data.replace('\n', ' ').split()
        
        for entry in entries:
            if ',' in entry:
                time_str, missing_count = entry.strip().split(',')
                try:
                    # è½‰æ›æ™‚é–“æ ¼å¼
                    hour, minute = map(int, time_str.split(':'))
                    time_slot = hour * 4 + minute // 15
                    missing_count = int(missing_count)
                    
                    self.time_outliers_data[time_slot] = {
                        'time': time_str,
                        'missing_count': missing_count,
                        'hour': hour,
                        'minute': minute
                    }
                except:
                    continue
        
        print(f"âœ“ Loaded time outliers data for {len(self.time_outliers_data)} time slots")
        
        # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
        missing_counts = [data['missing_count'] for data in self.time_outliers_data.values()]
        print(f"Missing data statistics:")
        print(f"  Min: {min(missing_counts)} occurrences")
        print(f"  Max: {max(missing_counts)} occurrences") 
        print(f"  Mean: {np.mean(missing_counts):.1f} occurrences")
        print(f"  Median: {np.median(missing_counts):.1f} occurrences")

    def detect_peak_hours(self):
        """æª¢æ¸¬ä½¿ç”¨é«˜å³°æ™‚æ®µ"""
        print("==== Detecting Peak Hours ====")
        
        if not self.time_outliers_data:
            print("âŒ No time outliers data available")
            return []
        
        missing_counts = [data['missing_count'] for data in self.time_outliers_data.values()]
        
        # ä½¿ç”¨çµ±è¨ˆæ–¹æ³•æª¢æ¸¬peak hours
        # ç¼ºå¤±æ•¸æ“šå°‘ = ä½¿ç”¨é »ç¹ = peak hour
        q25 = np.percentile(missing_counts, 25)
        threshold = q25  # ä½¿ç”¨ç¬¬ä¸€å››åˆ†ä½æ•¸ä½œç‚ºé–¾å€¼
        
        peak_hours = []
        for time_slot, data in self.time_outliers_data.items():
            if data['missing_count'] <= threshold:
                peak_hours.append({
                    'time_slot': time_slot,
                    'time': data['time'],
                    'hour': data['hour'],
                    'missing_count': data['missing_count'],
                    'usage_intensity': 1 - (data['missing_count'] - min(missing_counts)) / (max(missing_counts) - min(missing_counts))
                })
        
        # æŒ‰æ™‚é–“æ’åº
        peak_hours.sort(key=lambda x: x['time_slot'])
        self.peak_hours = peak_hours
        
        print(f"âœ“ Detected {len(peak_hours)} peak hour slots")
        print(f"Peak hours threshold: â‰¤ {threshold} missing occurrences")
        
        # é¡¯ç¤ºé€£çºŒçš„peak houræ™‚æ®µ
        if peak_hours:
            print("Peak hour periods:")
            current_start = peak_hours[0]['hour']
            current_end = peak_hours[0]['hour']
            
            for i, slot in enumerate(peak_hours[1:], 1):
                if slot['hour'] == current_end or slot['hour'] == current_end + 1:
                    current_end = slot['hour']
                else:
                    print(f"  {current_start:02d}:00 - {current_end:02d}:45 (å¼·åº¦: {np.mean([p['usage_intensity'] for p in peak_hours if current_start <= p['hour'] <= current_end]):.2f})")
                    current_start = slot['hour']
                    current_end = slot['hour']
                
                if i == len(peak_hours) - 1:
                    print(f"  {current_start:02d}:00 - {current_end:02d}:45 (å¼·åº¦: {np.mean([p['usage_intensity'] for p in peak_hours if current_start <= p['hour'] <= current_end]):.2f})")
        
        return peak_hours

    def detect_sleep_hours(self):
        """æª¢æ¸¬ç¡çœ /ä½ä½¿ç”¨æ™‚æ®µ"""
        print("==== Detecting Sleep Hours ====")
        
        if not self.time_outliers_data:
            print("âŒ No time outliers data available")
            return []
        
        missing_counts = [data['missing_count'] for data in self.time_outliers_data.values()]
        
        # ä½¿ç”¨çµ±è¨ˆæ–¹æ³•æª¢æ¸¬sleep hours
        # ç¼ºå¤±æ•¸æ“šå¤š = ä½¿ç”¨å°‘ = sleep hour
        q75 = np.percentile(missing_counts, 75)
        threshold = q75  # ä½¿ç”¨ç¬¬ä¸‰å››åˆ†ä½æ•¸ä½œç‚ºé–¾å€¼
        
        sleep_hours = []
        for time_slot, data in self.time_outliers_data.items():
            if data['missing_count'] >= threshold:
                sleep_hours.append({
                    'time_slot': time_slot,
                    'time': data['time'],
                    'hour': data['hour'],
                    'missing_count': data['missing_count'],
                    'sleep_intensity': (data['missing_count'] - min(missing_counts)) / (max(missing_counts) - min(missing_counts))
                })
        
        # æŒ‰æ™‚é–“æ’åº
        sleep_hours.sort(key=lambda x: x['time_slot'])
        self.sleep_hours = sleep_hours
        
        print(f"âœ“ Detected {len(sleep_hours)} sleep hour slots")
        print(f"Sleep hours threshold: â‰¥ {threshold} missing occurrences")
        
        # é¡¯ç¤ºé€£çºŒçš„sleep houræ™‚æ®µ
        if sleep_hours:
            print("Sleep hour periods:")
            current_start = sleep_hours[0]['hour']
            current_end = sleep_hours[0]['hour']
            
            for i, slot in enumerate(sleep_hours[1:], 1):
                if slot['hour'] == current_end or slot['hour'] == current_end + 1:
                    current_end = slot['hour']
                else:
                    print(f"  {current_start:02d}:00 - {current_end:02d}:45 (å¼·åº¦: {np.mean([s['sleep_intensity'] for s in sleep_hours if current_start <= s['hour'] <= current_end]):.2f})")
                    current_start = slot['hour']
                    current_end = slot['hour']
                
                if i == len(sleep_hours) - 1:
                    print(f"  {current_start:02d}:00 - {current_end:02d}:45 (å¼·åº¦: {np.mean([s['sleep_intensity'] for s in sleep_hours if current_start <= s['hour'] <= current_end]):.2f})")
        
        return sleep_hours

    def calculate_data_completeness_score(self):
        """è¨ˆç®—æ•¸æ“šå®Œæ•´æ€§åˆ†æ•¸"""
        print("==== Calculating Data Completeness Score ====")
        
        if not self.time_outliers_data:
            print("âŒ No time outliers data available")
            return {}
        
        missing_counts = [data['missing_count'] for data in self.time_outliers_data.values()]
        min_missing = min(missing_counts)
        max_missing = max(missing_counts)
        
        # è¨ˆç®—æ¯å€‹æ™‚æ®µçš„æ•¸æ“šå®Œæ•´æ€§åˆ†æ•¸
        for time_slot, data in self.time_outliers_data.items():
            missing_count = data['missing_count']
            
            # å®Œæ•´æ€§åˆ†æ•¸ï¼šç¼ºå¤±è¶Šå°‘ï¼Œåˆ†æ•¸è¶Šé«˜
            if max_missing > min_missing:
                completeness = 1.0 - (missing_count - min_missing) / (max_missing - min_missing)
            else:
                completeness = 1.0
            
            # ç¢ºä¿åˆ†æ•¸åœ¨[0,1]ç¯„åœå…§
            completeness = max(0.0, min(1.0, completeness))
            
            self.data_completeness_score[time_slot] = {
                'time': data['time'],
                'hour': data['hour'],
                'missing_count': missing_count,
                'completeness_score': completeness,
                'data_quality': 'high' if completeness >= 0.8 else 'medium' if completeness >= 0.5 else 'low'
            }
        
        # çµ±è¨ˆå„è³ªé‡ç­‰ç´šçš„æ™‚æ®µæ•¸
        quality_counts = {'high': 0, 'medium': 0, 'low': 0}
        for score_data in self.data_completeness_score.values():
            quality_counts[score_data['data_quality']] += 1
        
        print(f"âœ“ Calculated completeness scores for {len(self.data_completeness_score)} time slots")
        print(f"Data quality distribution:")
        print(f"  High quality (â‰¥0.8): {quality_counts['high']} slots")
        print(f"  Medium quality (0.5-0.8): {quality_counts['medium']} slots")
        print(f"  Low quality (<0.5): {quality_counts['low']} slots")
        
        return self.data_completeness_score

    def calculate_pattern_consistency_score(self):
        """è¨ˆç®—æ¨¡å¼ä¸€è‡´æ€§åˆ†æ•¸"""
        print("==== Calculating Pattern Consistency Score ====")
        
        if not self.peak_hours or not self.sleep_hours:
            print("âš ï¸  Peak hours or sleep hours not detected, using default consistency")
            return 0.5
        
        # æª¢æŸ¥peak hourså’Œsleep hoursçš„æ™‚é–“åˆ†ä½ˆæ˜¯å¦åˆç†
        peak_hour_set = set(p['hour'] for p in self.peak_hours)
        sleep_hour_set = set(s['hour'] for s in self.sleep_hours)
        
        # è¨ˆç®—æ¨¡å¼ä¸€è‡´æ€§
        # 1. Peak hoursæ‡‰è©²ä¸»è¦åœ¨æ™šä¸Š (18-23)
        evening_peak_hours = sum(1 for hour in peak_hour_set if 18 <= hour <= 23)
        evening_consistency = evening_peak_hours / len(peak_hour_set) if peak_hour_set else 0
        
        # 2. Sleep hoursæ‡‰è©²ä¸»è¦åœ¨æ·±å¤œ/å‡Œæ™¨ (0-7, 14-16)
        night_sleep_hours = sum(1 for hour in sleep_hour_set if hour <= 7 or 14 <= hour <= 16)
        night_consistency = night_sleep_hours / len(sleep_hour_set) if sleep_hour_set else 0
        
        # 3. Peakå’Œsleepæ™‚æ®µä¸æ‡‰è©²é‡ç–Š
        overlap = len(peak_hour_set & sleep_hour_set)
        overlap_penalty = overlap / max(len(peak_hour_set), len(sleep_hour_set)) if (peak_hour_set or sleep_hour_set) else 0
        
        # ç¶œåˆä¸€è‡´æ€§åˆ†æ•¸
        pattern_consistency = (evening_consistency * 0.4 + night_consistency * 0.4 + (1 - overlap_penalty) * 0.2)
        
        print(f"Pattern consistency analysis:")
        print(f"  Evening peak consistency: {evening_consistency:.2f}")
        print(f"  Night sleep consistency: {night_consistency:.2f}")
        print(f"  Peak-sleep overlap penalty: {overlap_penalty:.2f}")
        print(f"  Overall pattern consistency: {pattern_consistency:.2f}")
        
        return pattern_consistency

    def calculate_confidence_score(self, timestamp):
        """è¨ˆç®—æŒ‡å®šæ™‚é–“é»çš„ç½®ä¿¡åº¦åˆ†æ•¸ï¼ˆä¸ä½¿ç”¨ä¸‰è§’éš¸å±¬å‡½æ•¸ï¼‰"""
        try:
            # æå–æ™‚é–“ç‰¹å¾µ
            hour = timestamp.hour
            minute = timestamp.minute
            time_slot = hour * 4 + minute // 15
            
            result = {
                'hour': hour,
                'minute': minute,
                'time_slot': time_slot,
                'timestamp': timestamp
            }
            
            # 1. æ•¸æ“šå®Œæ•´æ€§åˆ†æ•¸
            if time_slot in self.data_completeness_score:
                completeness = self.data_completeness_score[time_slot]['completeness_score']
                data_quality = self.data_completeness_score[time_slot]['data_quality']
            else:
                completeness = 0.5
                data_quality = 'medium'
            
            # 2. æ™‚æ®µé¡å‹è­˜åˆ¥
            is_peak_hour = any(p['hour'] == hour for p in self.peak_hours)
            is_sleep_hour = any(s['hour'] == hour for s in self.sleep_hours)
            
            if is_peak_hour:
                time_pattern = 'peak'
                pattern_confidence = 0.9
            elif is_sleep_hour:
                time_pattern = 'sleep'
                pattern_confidence = 0.8
            else:
                time_pattern = 'normal'
                pattern_confidence = 0.6
            
            # 3. æ™‚é–“ç©©å®šæ€§è©•ä¼°ï¼ˆåŸºæ–¼ç›¸é„°æ™‚æ®µçš„ä¸€è‡´æ€§ï¼‰
            adjacent_consistency = self._calculate_adjacent_consistency(time_slot)
            
            # 4. ç¶œåˆç½®ä¿¡åº¦è¨ˆç®—ï¼ˆçµ±è¨ˆæ–¹æ³•ï¼Œéæ¨¡ç³Šé‚è¼¯ï¼‰
            weights = {
                'completeness': 0.4,      # æ•¸æ“šå®Œæ•´æ€§æ¬Šé‡æœ€é«˜
                'pattern': 0.35,          # æ¨¡å¼è­˜åˆ¥æ¬Šé‡
                'consistency': 0.25       # æ™‚é–“ä¸€è‡´æ€§æ¬Šé‡
            }
            
            confidence_score = (
                completeness * weights['completeness'] +
                pattern_confidence * weights['pattern'] +
                adjacent_consistency * weights['consistency']
            )
            
            # 5. æ·»åŠ åŸºæ–¼ä½¿ç”¨æ¨¡å¼çš„èª¿æ•´
            pattern_adjustment = self._get_pattern_adjustment(hour, is_peak_hour, is_sleep_hour)
            confidence_score += pattern_adjustment
            
            # ç¢ºä¿åˆ†æ•¸åœ¨[0,1]ç¯„åœå…§
            confidence_score = max(0.0, min(1.0, confidence_score))
            
            # è¨ˆç®—ç½®ä¿¡ç­‰ç´š
            if confidence_score >= 0.8:
                confidence_level = 'very_high'
            elif confidence_score >= 0.6:
                confidence_level = 'high'
            elif confidence_score >= 0.4:
                confidence_level = 'medium'
            elif confidence_score >= 0.2:
                confidence_level = 'low'
            else:
                confidence_level = 'very_low'
            
            result.update({
                'confidence_score': confidence_score,
                'confidence_level': confidence_level,
                'data_completeness': completeness,
                'data_quality': data_quality,
                'time_pattern': time_pattern,
                'pattern_confidence': pattern_confidence,
                'adjacent_consistency': adjacent_consistency,
                'is_peak_hour': is_peak_hour,
                'is_sleep_hour': is_sleep_hour
            })
            
            return result
            
        except Exception as e:
            print(f"âš ï¸  Error calculating confidence score: {e}")
            return {
                'confidence_score': 0.5,
                'confidence_level': 'medium',
                'error': str(e)
            }

    def _calculate_adjacent_consistency(self, time_slot):
        """è¨ˆç®—èˆ‡ç›¸é„°æ™‚æ®µçš„ä¸€è‡´æ€§"""
        try:
            if time_slot not in self.data_completeness_score:
                return 0.5
            
            current_score = self.data_completeness_score[time_slot]['completeness_score']
            adjacent_scores = []
            
            # æª¢æŸ¥å‰å¾Œå„2å€‹æ™‚æ®µ
            for offset in [-2, -1, 1, 2]:
                adj_slot = (time_slot + offset) % self.time_slots
                if adj_slot in self.data_completeness_score:
                    adjacent_scores.append(self.data_completeness_score[adj_slot]['completeness_score'])
            
            if not adjacent_scores:
                return 0.5
            
            # è¨ˆç®—èˆ‡ç›¸é„°æ™‚æ®µçš„ç›¸ä¼¼æ€§
            differences = [abs(current_score - adj_score) for adj_score in adjacent_scores]
            avg_difference = np.mean(differences)
            
            # ä¸€è‡´æ€§ = 1 - å¹³å‡å·®ç•°
            consistency = 1.0 - avg_difference
            
            return max(0.0, min(1.0, consistency))
            
        except:
            return 0.5

    def _get_pattern_adjustment(self, hour, is_peak_hour, is_sleep_hour):
        """åŸºæ–¼ä½¿ç”¨æ¨¡å¼çš„ç½®ä¿¡åº¦èª¿æ•´"""
        # åŸºæ–¼æ™‚é–“çš„é¡å¤–èª¿æ•´
        if is_peak_hour and 18 <= hour <= 23:
            return 0.1  # æ™šé–“peak hourï¼Œå¢åŠ ç½®ä¿¡åº¦
        elif is_sleep_hour and (0 <= hour <= 7 or 14 <= hour <= 16):
            return 0.05  # åˆç†çš„sleep hourï¼Œå°å¹…å¢åŠ ç½®ä¿¡åº¦
        elif is_peak_hour and not (18 <= hour <= 23):
            return -0.05  # éæ™šé–“çš„peak hourï¼Œç•¥é™ç½®ä¿¡åº¦
        elif is_sleep_hour and not (0 <= hour <= 7 or 14 <= hour <= 16):
            return -0.1  # éåˆç†æ™‚æ®µçš„sleep hourï¼Œé™ä½ç½®ä¿¡åº¦
        else:
            return 0.0  # æ­£å¸¸æ™‚æ®µï¼Œç„¡èª¿æ•´

    def plot_confidence_analysis(self):
        """ç¹ªè£½ç½®ä¿¡åº¦åˆ†æåœ–è¡¨"""
        if not self.time_outliers_data:
            print("âŒ No data available for plotting")
            return
        
        # æº–å‚™æ•¸æ“š
        hours = []
        missing_counts = []
        completeness_scores = []
        time_patterns = []
        
        for time_slot in range(0, self.time_slots, 4):  # æ¯å°æ™‚å–ä¸€å€‹é»
            if time_slot in self.time_outliers_data:
                hour = time_slot // 4
                hours.append(hour)
                missing_counts.append(self.time_outliers_data[time_slot]['missing_count'])
                
                if time_slot in self.data_completeness_score:
                    completeness_scores.append(self.data_completeness_score[time_slot]['completeness_score'])
                else:
                    completeness_scores.append(0.5)
                
                # åˆ¤æ–·æ™‚æ®µé¡å‹
                is_peak = any(p['hour'] == hour for p in self.peak_hours)
                is_sleep = any(s['hour'] == hour for s in self.sleep_hours)
                
                if is_peak:
                    time_patterns.append('Peak')
                elif is_sleep:
                    time_patterns.append('Sleep')
                else:
                    time_patterns.append('Normal')
        
        # å‰µå»ºåœ–è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Confidence Score Analysis Dashboard', fontsize=16, fontweight='bold')
        
        # 1. ç¼ºå¤±æ•¸æ“šåˆ†ä½ˆ
        ax1.plot(hours, missing_counts, 'b-', linewidth=2, marker='o', markersize=4)
        ax1.set_xlabel('Hour of Day')
        ax1.set_ylabel('Missing Data Count')
        ax1.set_title('Missing Data Distribution (24 Hours)')
        ax1.grid(True, alpha=0.3)
        ax1.set_xlim(0, 23)
        
        # æ¨™è¨˜peakå’Œsleepæ™‚æ®µ
        for p in self.peak_hours:
            if p['hour'] in hours:
                ax1.axvspan(p['hour']-0.3, p['hour']+0.3, alpha=0.2, color='green', label='Peak Hour' if p == self.peak_hours[0] else "")
        
        for s in self.sleep_hours:
            if s['hour'] in hours:
                ax1.axvspan(s['hour']-0.3, s['hour']+0.3, alpha=0.2, color='red', label='Sleep Hour' if s == self.sleep_hours[0] else "")
        
        ax1.legend()
        
        # 2. æ•¸æ“šå®Œæ•´æ€§åˆ†æ•¸
        ax2.plot(hours, completeness_scores, 'g-', linewidth=2, marker='s', markersize=4)
        ax2.set_xlabel('Hour of Day')
        ax2.set_ylabel('Completeness Score')
        ax2.set_title('Data Completeness Score (24 Hours)')
        ax2.grid(True, alpha=0.3)
        ax2.set_xlim(0, 23)
        ax2.set_ylim(0, 1)
        
        # æ·»åŠ é–¾å€¼ç·š
        ax2.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='High Quality')
        ax2.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Medium Quality')
        ax2.axhline(y=0.2, color='red', linestyle='--', alpha=0.5, label='Low Quality')
        ax2.legend()
        
        # 3. æ™‚æ®µé¡å‹åˆ†ä½ˆ
        pattern_counts = {'Peak': 0, 'Sleep': 0, 'Normal': 0}
        for pattern in time_patterns:
            pattern_counts[pattern] += 1
        
        colors = ['green', 'red', 'blue']
        ax3.pie(pattern_counts.values(), labels=pattern_counts.keys(), colors=colors, autopct='%1.1f%%', startangle=90)
        ax3.set_title('Time Pattern Distribution')
        
        # 4. ç½®ä¿¡åº¦ç†±åŠ›åœ–ï¼ˆ24å°æ™‚ï¼‰
        confidence_scores_24h = []
        for hour in range(24):
            test_time = datetime(2024, 6, 15, hour, 0)
            result = self.calculate_confidence_score(test_time)
            confidence_scores_24h.append(result['confidence_score'])
        
        # å‰µå»ºç†±åŠ›åœ–æ•¸æ“š
        heatmap_data = np.array(confidence_scores_24h).reshape(1, -1)
        
        im = ax4.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        ax4.set_xlabel('Hour of Day')
        ax4.set_title('Confidence Score Heatmap')
        ax4.set_xticks(range(0, 24, 4))
        ax4.set_xticklabels([f'{h:02d}' for h in range(0, 24, 4)])
        ax4.set_yticks([])
        
        # æ·»åŠ é¡è‰²æ¢
        plt.colorbar(im, ax=ax4, label='Confidence Score')
        
        plt.tight_layout()
        plt.show()
        
        # æ‰“å°çµ±è¨ˆä¿¡æ¯
        print("="*60)
        print("Confidence Score Analysis Summary")
        print("="*60)
        print(f"ğŸ“Š Peak Hours: {len(self.peak_hours)} time slots")
        if self.peak_hours:
            # ä¿®æ­£ï¼šæ­£ç¢ºè™•ç†å»é‡è¤‡çš„é‚è¼¯
            unique_peak_hours = []
            seen_hours = set()
            for p in self.peak_hours:
                if p['hour'] not in seen_hours:
                    unique_peak_hours.append(p)
                    seen_hours.add(p['hour'])
            
            # æŒ‰å°æ™‚æ’åº
            unique_peak_hours.sort(key=lambda x: x['hour'])
            peak_hours_str = ", ".join([f"{p['hour']:02d}:xx" for p in unique_peak_hours])
            print(f"   Hours: {peak_hours_str}")
        
        print(f"ğŸ“Š Sleep Hours: {len(self.sleep_hours)} time slots")
        if self.sleep_hours:
            # ä¿®æ­£ï¼šæ­£ç¢ºè™•ç†å»é‡è¤‡çš„é‚è¼¯
            unique_sleep_hours = []
            seen_hours = set()
            for s in self.sleep_hours:
                if s['hour'] not in seen_hours:
                    unique_sleep_hours.append(s)
                    seen_hours.add(s['hour'])
            
            # æŒ‰å°æ™‚æ’åº
            unique_sleep_hours.sort(key=lambda x: x['hour'])
            sleep_hours_str = ", ".join([f"{s['hour']:02d}:xx" for s in unique_sleep_hours])
            print(f"   Hours: {sleep_hours_str}")
        
        print(f"ğŸ“Š Data Quality Distribution:")
        for quality, count in pattern_counts.items():
            print(f"   {quality}: {count} hours ({count/24*100:.1f}%)")
        
        avg_confidence = np.mean(confidence_scores_24h)
        print(f"ğŸ“Š Average Confidence Score: {avg_confidence:.3f}")

    def test_confidence_score_calculation(self, num_tests=5):
        """æ¸¬è©¦ç½®ä¿¡åº¦åˆ†æ•¸è¨ˆç®—åŠŸèƒ½"""
        print("==== Testing Confidence Score Calculation ====")
        
        test_times = [
            datetime(2024, 1, 15, 9, 0),   # é€±ä¸€æ—©ä¸Š9é»
            datetime(2024, 1, 15, 14, 30), # é€±ä¸€ä¸‹åˆ2:30
            datetime(2024, 1, 15, 21, 0),  # é€±ä¸€æ™šä¸Š9é» (å¯èƒ½æ˜¯peak)
            datetime(2024, 1, 13, 3, 15),  # é€±å…­å‡Œæ™¨3:15 (å¯èƒ½æ˜¯sleep)
            datetime(2024, 1, 13, 19, 45), # é€±å…­æ™šä¸Š7:45 (å¯èƒ½æ˜¯peak)
        ]
        
        test_results = []
        
        for i, test_time in enumerate(test_times[:num_tests]):
            try:
                result = self.calculate_confidence_score(test_time)
                
                day_type = "Weekend" if test_time.weekday() >= 5 else "Weekday"
                print(f"\nTest {i+1}: {test_time.strftime('%Y-%m-%d %H:%M')} ({day_type})")
                print(f"  Confidence Score: {result['confidence_score']:.3f}")
                print(f"  Confidence Level: {result['confidence_level']}")
                print(f"  Time Pattern: {result['time_pattern']}")
                print(f"  Data Quality: {result['data_quality']}")
                print(f"  Data Completeness: {result['data_completeness']:.3f}")
                print(f"  Is Peak Hour: {result['is_peak_hour']}")
                print(f"  Is Sleep Hour: {result['is_sleep_hour']}")
                
                test_results.append({
                    'time': test_time,
                    'confidence_score': result['confidence_score'],
                    'confidence_level': result['confidence_level'],
                    'time_pattern': result['time_pattern']
                })
                
            except Exception as e:
                print(f"âš ï¸  Error in test {i+1}: {e}")
                test_results.append({
                    'time': test_time,
                    'confidence_score': 0.5,
                    'confidence_level': 'medium',
                    'time_pattern': 'unknown'
                })
        
        return test_results

    def comprehensive_evaluation(self):
        """å®Œæ•´çš„ç³»çµ±è©•ä¼°"""
        print("\n" + "="*60)
        print("CONFIDENCE SCORE MODULE - COMPREHENSIVE EVALUATION")
        print("="*60)
        
        # 1. æ•¸æ“šå®Œæ•´æ€§è©•ä¼°
        if self.data_completeness_score:
            completeness_scores = [data['completeness_score'] for data in self.data_completeness_score.values()]
            avg_completeness = np.mean(completeness_scores)
            min_completeness = np.min(completeness_scores)
            max_completeness = np.max(completeness_scores)
            
            print(f"\n1. Data Completeness Assessment:")
            print(f"   Average Completeness: {avg_completeness:.3f}")
            print(f"   Range: {min_completeness:.3f} - {max_completeness:.3f}")
            print(f"   Data Quality Distribution:")
            
            quality_counts = {'high': 0, 'medium': 0, 'low': 0}
            for data in self.data_completeness_score.values():
                quality_counts[data['data_quality']] += 1
            
            for quality, count in quality_counts.items():
                percentage = count / len(self.data_completeness_score) * 100
                print(f"     {quality.capitalize()}: {count} slots ({percentage:.1f}%)")
        
        # 2. æ¨¡å¼æª¢æ¸¬è©•ä¼°
        print(f"\n2. Pattern Detection Assessment:")
        print(f"   Peak Hours Detected: {len(self.peak_hours)} time slots")
        print(f"   Sleep Hours Detected: {len(self.sleep_hours)} time slots")
        
        # è¨ˆç®—æ¨¡å¼è¦†è“‹ç‡
        total_pattern_coverage = (len(self.peak_hours) + len(self.sleep_hours)) / self.time_slots * 100
        print(f"   Pattern Coverage: {total_pattern_coverage:.1f}% of all time slots")
        
        # 3. æ¨¡å¼ä¸€è‡´æ€§è©•ä¼°
        pattern_consistency = self.calculate_pattern_consistency_score()
        print(f"\n3. Pattern Consistency: {pattern_consistency:.3f}")
        
        # 4. ç½®ä¿¡åº¦åˆ†æ•¸æ¸¬è©¦
        print(f"\n4. Confidence Score Tests:")
        test_scenarios = [
            (datetime(2024, 1, 15, 9, 0), (0.4, 0.8), 'å·¥ä½œæ—¥æ—©ä¸Š'),
            (datetime(2024, 1, 15, 15, 0), (0.2, 0.6), 'å·¥ä½œæ—¥ä¸‹åˆ'),  # å¯èƒ½æ˜¯sleepæ™‚æ®µ
            (datetime(2024, 1, 15, 21, 0), (0.6, 1.0), 'å·¥ä½œæ—¥æ™šä¸Š'),  # å¯èƒ½æ˜¯peakæ™‚æ®µ
            (datetime(2024, 1, 13, 3, 0), (0.3, 0.7), 'é€±æœ«å‡Œæ™¨'),   # å¯èƒ½æ˜¯sleepæ™‚æ®µ
            (datetime(2024, 1, 13, 19, 0), (0.5, 0.9), 'é€±æœ«æ™šä¸Š'),  # å¯èƒ½æ˜¯peakæ™‚æ®µ
        ]
        
        passed_tests = 0
        for test_time, expected_range, desc in test_scenarios:
            try:
                result = self.calculate_confidence_score(test_time)
                score = result['confidence_score']
                
                is_reasonable = expected_range[0] <= score <= expected_range[1]
                
                if is_reasonable:
                    passed_tests += 1
                    status = 'âœ“'
                else:
                    status = 'âŒ'
                
                print(f"   {status} {desc}: {score:.3f} (æœŸæœ›: {expected_range}) - {result['time_pattern']}")
            except Exception as e:
                print(f"   âŒ {desc}: Error - {e}")
        
        # 5. æœ€çµ‚è©•åˆ†
        print(f"\n=== FINAL ASSESSMENT ===")
        
        # è¨ˆç®—å„é …åˆ†æ•¸
        data_quality_score = avg_completeness if self.data_completeness_score else 0
        pattern_detection_score = min(1.0, total_pattern_coverage / 50)  # 50%è¦†è“‹ç‡ç‚ºæ»¿åˆ†
        test_pass_rate = passed_tests / len(test_scenarios)
        
        overall_score = (data_quality_score * 0.4 + pattern_consistency * 0.3 + 
                        pattern_detection_score * 0.2 + test_pass_rate * 0.1)
        
        print(f"Data Quality Score: {data_quality_score:.2f}")
        print(f"Pattern Consistency: {pattern_consistency:.2f}")
        print(f"Pattern Detection Score: {pattern_detection_score:.2f}")
        print(f"Test Pass Rate: {test_pass_rate:.2f}")
        print(f"Overall System Quality: {overall_score:.2f}")
        
        if overall_score >= 0.8:
            print("ğŸ‰ System Quality: Excellent")
        elif overall_score >= 0.6:
            print("âœ… System Quality: Good") 
        elif overall_score >= 0.4:
            print("âš ï¸  System Quality: Acceptable")
        else:
            print("âŒ System Quality: Needs Improvement")

    def run_complete_analysis(self):
        """é‹è¡Œå®Œæ•´åˆ†æ"""
        print("="*80)
        print("CONFIDENCE SCORE MODULE - COMPLETE ANALYSIS")
        print("="*80)

        # 1. æª¢æ¸¬é«˜å³°æ™‚æ®µ
        print("\n" + "-"*50)
        self.detect_peak_hours()
        
        # 2. æª¢æ¸¬ç¡çœ æ™‚æ®µ
        print("\n" + "-"*50)
        self.detect_sleep_hours()
        
        # 3. è¨ˆç®—æ•¸æ“šå®Œæ•´æ€§åˆ†æ•¸
        print("\n" + "-"*50)
        self.calculate_data_completeness_score()

        # 4. æ¸¬è©¦ç½®ä¿¡åº¦è¨ˆç®—
        print("\n" + "-"*50)
        test_results = self.test_confidence_score_calculation()

        # 5. ç¶œåˆè©•ä¼°
        print("\n" + "-"*50)
        self.comprehensive_evaluation()

        # 6. ç¹ªè£½åˆ†æåœ–è¡¨
        print("\n" + "-"*50)
        print("==== Plotting Confidence Analysis Dashboard ====")
        self.plot_confidence_analysis()

        print("\n" + "="*80)
        print("âœ… ANALYSIS COMPLETE - Confidence Score system ready!")
        print("="*80)

        return {
            'peak_hours': self.peak_hours,
            'sleep_hours': self.sleep_hours,
            'data_completeness_score': self.data_completeness_score,
            'time_outliers_data': self.time_outliers_data,
            'test_results': test_results
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–ç½®ä¿¡åº¦åˆ†æ•¸æ¨¡çµ„
    confidence_module = ConfidenceScoreModule()
    
    # é‹è¡Œå®Œæ•´åˆ†æ
    result = confidence_module.run_complete_analysis()
    
    # å–®ç¨æ¸¬è©¦ç½®ä¿¡åº¦åˆ†æ•¸è¨ˆç®—
    if result:
        print("\n" + "="*50)
        print("TESTING INDIVIDUAL CONFIDENCE SCORE CALCULATIONS")
        print("="*50)
        
        # æ¸¬è©¦å¹¾å€‹ç‰¹å®šæ™‚é–“é»
        test_times = [
            datetime(2024, 6, 15, 8, 30),   # é€±å…­æ—©ä¸Š8:30
            datetime(2024, 6, 17, 19, 45),  # é€±ä¸€æ™šä¸Š7:45 (peak hour)
            datetime(2024, 6, 20, 15, 15),  # é€±å››ä¸‹åˆ3:15 (sleep hour)
            datetime(2024, 6, 18, 3, 0),    # é€±äºŒå‡Œæ™¨3é» (sleep hour)
        ]
        
        for test_time in test_times:
            result = confidence_module.calculate_confidence_score(test_time)
            day_type = "Weekend" if test_time.weekday() >= 5 else "Weekday"
            
            print(f"\næ™‚é–“: {test_time.strftime('%Y-%m-%d %H:%M')} ({day_type})")
            print(f"ç½®ä¿¡åº¦åˆ†æ•¸: {result['confidence_score']:.3f}")
            print(f"ç½®ä¿¡åº¦ç­‰ç´š: {result['confidence_level']}")
            print(f"æ™‚æ®µæ¨¡å¼: {result['time_pattern']}")
            print(f"æ•¸æ“šè³ªé‡: {result['data_quality']}")
            
            # æä¾›è§£é‡‹
            if result['confidence_score'] >= 0.8:
                explanation = "ğŸŸ¢ ç½®ä¿¡åº¦å¾ˆé«˜ï¼Œæ•¸æ“šå¯é æ€§æ¥µä½³"
            elif result['confidence_score'] >= 0.6:
                explanation = "ğŸŸ¡ ç½®ä¿¡åº¦é«˜ï¼Œæ•¸æ“šå¯é "
            elif result['confidence_score'] >= 0.4:
                explanation = "ğŸŸ  ç½®ä¿¡åº¦ä¸­ç­‰ï¼Œæ•¸æ“šåŸºæœ¬å¯ä¿¡"
            else:
                explanation = "ğŸ”´ ç½®ä¿¡åº¦è¼ƒä½ï¼Œå»ºè­°è¬¹æ…ä½¿ç”¨æ•¸æ“š"
            
            print(f"è§£é‡‹: {explanation}")
        
        print(f"\nğŸ’¡ æç¤ºï¼šå¦‚æœæƒ³é‡æ–°æŸ¥çœ‹ç½®ä¿¡åº¦åˆ†æåœ–è¡¨ï¼Œå¯ä»¥é‹è¡Œï¼š")
        print(f"confidence_module.plot_confidence_analysis()")