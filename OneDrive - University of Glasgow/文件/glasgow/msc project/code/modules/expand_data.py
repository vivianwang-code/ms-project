import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random
from collections import defaultdict

class PowerDataExpander():
    def __init__(self, csv_path):
        """
        åˆå§‹åŒ–æ•¸æ“šæ“´å±•å™¨ï¼ˆåªæ”¯æŒå¾€å‰æ–°å¢ï¼‰
        """
        self.original_data = None
        self.hourly_patterns = {}
        self.weekday_patterns = {}
        self.transition_patterns = {}
        self.missing_patterns = {}

        self.load_original_data(csv_path) 
        
    def load_original_data(self, csv_path):
        """
        è¼‰å…¥é è™•ç†å¾Œçš„CSVæ•¸æ“š
        """
        try:
            print(f"csv_path : {csv_path}")
            self.original_data = pd.read_csv(csv_path)
            self.original_data['timestamp'] = pd.to_datetime(self.original_data['timestamp'], format='ISO8601')
            
            # æ’åºæ•¸æ“š
            self.original_data = self.original_data.sort_values('timestamp').reset_index(drop=True)
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.original_data)} ç­†åŸå§‹æ•¸æ“š")
            print(f"ğŸ“… æ™‚é–“ç¯„åœï¼š{self.original_data['timestamp'].min()} åˆ° {self.original_data['timestamp'].max()}")
            
            # é¡¯ç¤ºæ•¸æ“šæ¡æ¨£é »ç‡
            if len(self.original_data) > 1:
                time_diff = (self.original_data.iloc[1]['timestamp'] - self.original_data.iloc[0]['timestamp']).total_seconds()
                print(f"ğŸ“Š æ•¸æ“šæ¡æ¨£é–“éš”ï¼š{time_diff:.0f} ç§’")
            
            return True
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ {csv_path}")
            print("ğŸ’¡ è«‹ç¢ºä¿æ–‡ä»¶åœ¨ç•¶å‰ç›®éŒ„ä¸‹ï¼Œæˆ–æä¾›æ­£ç¢ºçš„æ–‡ä»¶è·¯å¾‘")
            return False
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return False
    
    def _calculate_time_diff(self, data):
        """
        è¨ˆç®—ç›¸é„°è¨˜éŒ„ä¹‹é–“çš„æ™‚é–“å·®ï¼ˆç§’ï¼‰
        """
        time_diffs = []
        
        for i in range(len(data)):
            if i == 0:
                time_diffs.append(None)  # ç¬¬ä¸€ç­†è¨˜éŒ„æ²’æœ‰å‰ä¸€ç­†
            else:
                time_diff = (data.iloc[i]['timestamp'] - data.iloc[i-1]['timestamp']).total_seconds()
                time_diffs.append(time_diff)
        
        return time_diffs

    def _print_time_diff_stats(self, data):
        """
        é¡¯ç¤ºæ™‚é–“å·®çµ±è¨ˆè³‡è¨Š
        """
        valid_diffs = data['time_diff_seconds'].dropna()
        
        if len(valid_diffs) > 0:
            print(f"\nâ±ï¸  æ™‚é–“é–“éš”çµ±è¨ˆï¼š")
            print(f"   æ¨™æº–é–“éš”ï¼ˆ900ç§’ï¼‰ï¼š{(valid_diffs == 900).sum()} ç­†")
            print(f"   éæ¨™æº–é–“éš”ï¼š{(valid_diffs != 900).sum()} ç­†")
            print(f"   å¹³å‡é–“éš”ï¼š{valid_diffs.mean():.1f} ç§’")
            print(f"   æœ€å¤§é–“éš”ï¼š{valid_diffs.max():.1f} ç§’")
            print(f"   æœ€å°é–“éš”ï¼š{valid_diffs.min():.1f} ç§’")
            
            # åˆ†æç¼ºå¤±æ•¸æ“šæ¨¡å¼
            gaps = valid_diffs[valid_diffs > 900]
            if len(gaps) > 0:
                print(f"   ç™¼ç¾ {len(gaps)} å€‹æ•¸æ“šç¼ºå¤±é–“éš”")
                print(f"   æœ€å¤§ç¼ºå¤±ï¼š{gaps.max():.0f} ç§’ ({gaps.max()/3600:.1f} å°æ™‚)")

    def _generate_missing_columns(self, data):
        """
        æ ¹æ“š power å€¼ç”Ÿæˆç¼ºå¤±çš„åˆ†é¡æ¬„ä½
        """
        # ä½¿ç”¨ç°¡å–®çš„é–¾å€¼åˆ†é¡ï¼ˆæ‚¨å¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´ï¼‰
        data['is_phantom_load'] = data['power'] <= 35
        data['is_light_use'] = (data['power'] > 35) & (data['power'] <= 75)
        data['is_regular_use'] = data['power'] > 75
        
        # ç”Ÿæˆ power_state æ¬„ä½
        conditions = [
            data['is_phantom_load'],
            data['is_light_use'],
            data['is_regular_use']
        ]
        choices = ['phantom load', 'light use', 'regular use']
        data['power_state'] = np.select(conditions, choices, default='unknown')
        
        print("âœ… å·²æ ¹æ“š power å€¼è‡ªå‹•ç”Ÿæˆåˆ†é¡æ¬„ä½")
        return data
    
    def analyze_patterns(self):
        """
        åˆ†æåŸå§‹æ•¸æ“šçš„ä½¿ç”¨æ¨¡å¼
        """
        if self.original_data is None:
            raise ValueError("è«‹å…ˆè¼‰å…¥åŸå§‹æ•¸æ“š")
        
        data = self.original_data.copy()
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        data = data.sort_values('timestamp').reset_index(drop=True)
        
        # è¨ˆç®—æ™‚é–“å·®
        data['time_diff_seconds'] = self._calculate_time_diff(data)
        
        # æª¢æŸ¥ä¸¦å‰µå»ºå¿…è¦çš„æ¬„ä½
        required_columns = ['is_phantom_load', 'is_light_use', 'is_regular_use', 'power_state']
        for col in required_columns:
            if col not in data.columns:
                print(f"âš ï¸  æ¬„ä½ '{col}' ä¸å­˜åœ¨ï¼Œå°‡æ ¹æ“š power å€¼è‡ªå‹•ç”Ÿæˆ")
                data = self._generate_missing_columns(data)
                break
        
        data['hour'] = data['timestamp'].dt.hour
        data['weekday'] = data['timestamp'].dt.weekday
        data['is_weekend'] = data['weekday'].isin([5, 6])
        data['time_slot'] = data['hour'].apply(self._get_time_slot)
        
        print("ğŸ” é–‹å§‹åˆ†ææ•¸æ“šæ¨¡å¼...")
        
        # é¡¯ç¤ºæ™‚é–“å·®çµ±è¨ˆ
        self._print_time_diff_stats(data)
        
        # 1. åˆ†ææ¯å°æ™‚çš„åŠŸç‡åˆ†ä½ˆ
        self._analyze_hourly_patterns(data)
        
        # 2. åˆ†æå·¥ä½œæ—¥vsé€±æœ«æ¨¡å¼
        self._analyze_weekday_patterns(data)
        
        # 3. åˆ†æç‹€æ…‹è½‰æ›æ¨¡å¼
        self._analyze_transition_patterns(data)
        
        # 4. åˆ†æç¼ºå¤±æ•¸æ“šæ¨¡å¼
        self._analyze_missing_patterns(data)
        
        print("âœ… æ¨¡å¼åˆ†æå®Œæˆ")
    
    def _analyze_hourly_patterns(self, data):
        """
        åˆ†ææ¯å°æ™‚çš„ä½¿ç”¨æ¨¡å¼
        """
        for hour in range(24):
            hour_data = data[data['hour'] == hour]
            if len(hour_data) > 0:
                self.hourly_patterns[hour] = {
                    'power_mean': hour_data['power'].mean(),
                    'power_std': hour_data['power'].std(),
                    'power_min': hour_data['power'].min(),
                    'power_max': hour_data['power'].max(),
                    'phantom_prob': hour_data['is_phantom_load'].mean(),
                    'light_prob': hour_data['is_light_use'].mean(),
                    'regular_prob': hour_data['is_regular_use'].mean(),
                    'count': len(hour_data)
                }
        
        print(f"ğŸ“Š åˆ†æäº† {len(self.hourly_patterns)} å€‹å°æ™‚çš„æ¨¡å¼")
    
    def _analyze_weekday_patterns(self, data):
        """
        åˆ†æå·¥ä½œæ—¥vsé€±æœ«æ¨¡å¼
        """
        for is_weekend in [False, True]:
            weekend_data = data[data['is_weekend'] == is_weekend]
            day_type = "é€±æœ«" if is_weekend else "å·¥ä½œæ—¥"
            
            if len(weekend_data) > 0:
                self.weekday_patterns[is_weekend] = {
                    'power_mean': weekend_data['power'].mean(),
                    'power_std': weekend_data['power'].std(),
                    'phantom_prob': weekend_data['is_phantom_load'].mean(),
                    'light_prob': weekend_data['is_light_use'].mean(),
                    'regular_prob': weekend_data['is_regular_use'].mean(),
                    'count': len(weekend_data)
                }
                print(f"ğŸ“ˆ {day_type}ï¼šå¹³å‡åŠŸç‡ {weekend_data['power'].mean():.1f}W")
    
    def _analyze_transition_patterns(self, data):
        """
        åˆ†æç‹€æ…‹è½‰æ›æ¨¡å¼
        """
        data_sorted = data.sort_values('timestamp')
        data_sorted['prev_state'] = data_sorted['power_state'].shift(1)
        
        transitions = data_sorted.groupby(['prev_state', 'power_state']).size()
        total_transitions = len(data_sorted) - 1
        
        for (prev_state, curr_state), count in transitions.items():
            if pd.notna(prev_state):
                key = f"{prev_state}â†’{curr_state}"
                self.transition_patterns[key] = {
                    'probability': count / total_transitions,
                    'count': count
                }
        
        print(f"ğŸ”„ åˆ†æäº† {len(self.transition_patterns)} ç¨®ç‹€æ…‹è½‰æ›")
    
    def _analyze_missing_patterns(self, data):
        """
        åˆ†æç¼ºå¤±æ•¸æ“šæ¨¡å¼ï¼ˆåŸºæ–¼æ™‚é–“å·®ç•°ï¼‰
        """
        print(f"ğŸ“‰ åˆ†ææ•¸æ“šç¼ºå¤±æ¨¡å¼...")
        
        # åˆ†ææ™‚é–“é–“éš”ï¼Œè­˜åˆ¥å¯èƒ½çš„ç¼ºå¤±æ¨¡å¼
        data_sorted = data.sort_values('timestamp')
        
        # æ‰¾å‡ºéæ¨™æº–é–“éš”ï¼ˆä¸æ˜¯900ç§’çš„ï¼‰
        valid_time_diffs = data_sorted['time_diff_seconds'].dropna()
        non_standard = data_sorted[data_sorted['time_diff_seconds'] > 900]
        
        print(f"   ç¸½æ™‚é–“é–“éš”ï¼š{len(valid_time_diffs)} å€‹")
        print(f"   éæ¨™æº–é–“éš”ï¼š{len(non_standard)} å€‹")
        
        # æŒ‰å°æ™‚åˆ†æç¼ºå¤±ç‡
        for hour in range(24):
            hour_data = data_sorted[data_sorted['hour'] == hour]
            hour_missing = non_standard[non_standard['hour'] == hour]
            
            if len(hour_data) > 0:
                missing_prob = len(hour_missing) / len(hour_data)
                self.missing_patterns[hour] = min(0.15, missing_prob)  # é™åˆ¶æœ€å¤§ç¼ºå¤±ç‡15%
            else:
                self.missing_patterns[hour] = 0.02  # é è¨­ç¼ºå¤±ç‡2%
        
        # é¡¯ç¤ºç¼ºå¤±ç‡æœ€é«˜çš„æ™‚æ®µ
        sorted_missing = sorted(self.missing_patterns.items(), key=lambda x: x[1], reverse=True)
        print(f"   ç¼ºå¤±ç‡æœ€é«˜çš„æ™‚æ®µï¼š")
        for hour, rate in sorted_missing[:5]:
            print(f"     {hour:02d}:00 - {rate:.1%}")
        
        print(f"   å®Œæˆå„æ™‚æ®µçš„æ•¸æ“šç¼ºå¤±æ¨¡å¼åˆ†æ")
    
    def _get_time_slot(self, hour):
        """
        å°‡å°æ™‚è½‰æ›ç‚ºæ™‚æ®µ
        """
        if 6 <= hour <= 9:
            return "morning"
        elif 10 <= hour <= 17:
            return "daytime"
        elif 18 <= hour <= 22:
            return "evening"
        else:
            return "night"
    
    def generate_extended_data(self, weeks=8):
        """
        å¾€å‰ç”Ÿæˆæ“´å±•æ•¸æ“šï¼ˆåœ¨åŸå§‹æ•¸æ“šä¹‹å‰å¢åŠ æ­·å²æ•¸æ“šï¼‰
        """
        if not self.hourly_patterns:
            self.analyze_patterns()
        
        # ç¢ºå®šæ–°çš„æ™‚é–“ç¯„åœï¼ˆå¾€å‰ç”Ÿæˆï¼‰
        original_start = self.original_data['timestamp'].min()
        new_start = original_start - timedelta(weeks=weeks)
        new_end = original_start
        
        print(f"ğŸš€ é–‹å§‹å¾€å‰ç”Ÿæˆ {weeks} é€±çš„æ­·å²æ•¸æ“š...")
        print(f"ğŸ“… æ–°æ™‚é–“ç¯„åœï¼š{new_start.date()} åˆ° {new_end.date()}")
        print(f"ğŸ”— å°‡èˆ‡åŸå§‹æ•¸æ“šï¼ˆ{original_start.date()} é–‹å§‹ï¼‰é€£æ¥")
        
        # ç”Ÿæˆ15åˆ†é˜é–“éš”çš„æ™‚é–“åºåˆ—
        time_range = pd.date_range(start=new_start, end=new_end, freq='15min')
        print(f"ğŸ“ é è¨ˆç”Ÿæˆï¼š{len(time_range):,} ç­†è¨˜éŒ„")
        
        extended_records = []
        
        # ç²å–åŸå§‹æ•¸æ“šé–‹å§‹æ™‚çš„ç‹€æ…‹ä½œç‚ºçµæŸç‹€æ…‹
        target_end_state = self._get_original_start_state()
        prev_power_state = "phantom load"  # åˆå§‹ç‹€æ…‹
        
        for i, timestamp in enumerate(time_range):
            # è¨ˆç®—æ™‚é–“å·®
            time_diff = 900.0 if i > 0 else None  # 15åˆ†é˜ = 900ç§’
            
            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²æ¨¡æ“¬ç¼ºå¤±æ•¸æ“š
            if self._should_skip_record(timestamp):
                if i > 0 and extended_records:
                    # æ›´æ–°ä¸Šä¸€ç­†è¨˜éŒ„çš„æ™‚é–“å·®
                    extended_records[-1]['time_diff_seconds'] = extended_records[-1].get('time_diff_seconds', 0) + 900
                continue
            
            # ç”ŸæˆåŠŸç‡å’Œç‹€æ…‹ï¼ˆéš¨è‘—æ™‚é–“æ¥è¿‘åŸå§‹æ•¸æ“šï¼Œç‹€æ…‹æœƒè¶¨å‘æ–¼target_end_stateï¼‰
            power, power_state = self._generate_power_and_state_with_trend(
                timestamp, prev_power_state, target_end_state, new_start, new_end
            )
            prev_power_state = power_state
            
            # å‰µå»ºè¨˜éŒ„
            record = {
                'timestamp': timestamp,
                'power': power,
                'power_state': power_state,
                'is_phantom_load': power_state == 'phantom load',
                'is_off': False,
                'is_on': True,
                'is_light_use': power_state == 'light use',
                'is_regular_use': power_state == 'regular use',
                'time_diff_seconds': time_diff
            }
            
            extended_records.append(record)
        
        # è½‰æ›ç‚ºDataFrame
        extended_df = pd.DataFrame(extended_records)
        
        print(f"âœ… ç”Ÿæˆå®Œæˆï¼š{len(extended_df):,} ç­†è¨˜éŒ„")
        
        return extended_df

    def _get_original_start_state(self):
        """
        ç²å–åŸå§‹æ•¸æ“šé–‹å§‹æ™‚çš„ä¸»è¦ç‹€æ…‹
        """
        if len(self.original_data) > 0:
            # ä½¿ç”¨åŸå§‹æ•¸æ“šå‰100ç­†è¨˜éŒ„çš„ä¸»è¦ç‹€æ…‹
            first_records = self.original_data.head(100)
            
            if 'power_state' in first_records.columns:
                most_common_state = first_records['power_state'].mode().iloc[0]
                return most_common_state
            else:
                # æ ¹æ“šåŠŸç‡å€¼æ¨æ–·
                avg_power = first_records['power'].mean()
                if avg_power <= 35:
                    return 'phantom load'
                elif avg_power <= 75:
                    return 'light use'
                else:
                    return 'regular use'
        
        return "phantom load"  # é è¨­å€¼
    
    def _should_skip_record(self, timestamp):
        """
        æ ¹æ“šå­¸ç¿’åˆ°çš„ç¼ºå¤±æ¨¡å¼æ±ºå®šæ˜¯å¦è·³éè¨˜éŒ„
        """
        hour = timestamp.hour
        missing_prob = self.missing_patterns.get(hour, 0.02)
        
        # æ·»åŠ ä¸€äº›éš¨æ©Ÿæ€§
        return np.random.random() < missing_prob
    
    def _generate_power_and_state_with_trend(self, timestamp, prev_state, target_state, start_time, end_time):
        """
        ç”ŸæˆåŠŸç‡å’Œç‹€æ…‹ï¼Œéš¨æ™‚é–“è¶¨å‘ç›®æ¨™ç‹€æ…‹
        """
        hour = timestamp.hour
        weekday = timestamp.weekday()
        is_weekend = weekday >= 5
        
        # ç²å–è©²å°æ™‚çš„åŸºç¤æ¨¡å¼
        if hour in self.hourly_patterns:
            hour_pattern = self.hourly_patterns[hour]
        else:
            hour_pattern = {
                'power_mean': self.original_data['power'].mean(),
                'power_std': self.original_data['power'].std(),
                'phantom_prob': 0.76,
                'light_prob': 0.20,
                'regular_prob': 0.04
            }
        
        # è¨ˆç®—æ™‚é–“é€²åº¦ï¼ˆ0=é–‹å§‹ï¼Œ1=çµæŸï¼‰
        progress = (timestamp - start_time).total_seconds() / (end_time - start_time).total_seconds()
        
        # ç‹€æ…‹æ¦‚ç‡èª¿æ•´ï¼ˆéš¨æ™‚é–“è¶¨å‘ç›®æ¨™ç‹€æ…‹ï¼‰
        state_probs = self._get_state_probabilities_with_trend(hour_pattern, prev_state, target_state, progress)
        
        # é€±æœ«èª¿æ•´å› å­
        weekend_factor = 1.0
        if is_weekend and self.weekday_patterns:
            weekend_factor = self.weekday_patterns.get(True, {}).get('power_mean', 1) / \
                           self.weekday_patterns.get(False, {}).get('power_mean', 1)
        
        # éš¨æ©Ÿé¸æ“‡ç‹€æ…‹
        rand = np.random.random()
        if rand < state_probs['phantom']:
            power_state = 'phantom load'
            power = np.random.normal(18, 2)
            power = np.clip(power, 16, 35)
        elif rand < state_probs['phantom'] + state_probs['light']:
            power_state = 'light use'
            power = np.random.normal(55, 10)
            power = np.clip(power, 37, 75)
        else:
            power_state = 'regular use'
            power = np.random.normal(90, 20)
            power = np.clip(power, 80, 173)
        
        # æ‡‰ç”¨é€±æœ«å› å­å’Œæ·»åŠ è®Šç•°
        power *= weekend_factor
        power *= np.random.normal(1.0, 0.05)  # 5%çš„éš¨æ©Ÿè®Šç•°
        
        # ç¢ºä¿åŠŸç‡å€¼åœ¨åˆç†ç¯„åœå…§
        power = round(max(16, min(173, power)), 1)
        
        return power, power_state

    def _get_state_probabilities_with_trend(self, hour_pattern, prev_state, target_state, progress):
        """
        åŸºæ–¼å°æ™‚æ¨¡å¼ã€å‰ä¸€ç‹€æ…‹å’Œç›®æ¨™ç‹€æ…‹è¨ˆç®—ç‹€æ…‹æ¦‚ç‡
        progress: 0-1ï¼Œè¡¨ç¤ºæ™‚é–“é€²åº¦
        """
        base_probs = {
            'phantom': hour_pattern.get('phantom_prob', 0.76),
            'light': hour_pattern.get('light_prob', 0.20),
            'regular': hour_pattern.get('regular_prob', 0.04)
        }
        
        # ç‹€æ…‹æŒçºŒæ€§èª¿æ•´
        persistence_factor = 0.3
        if prev_state in ['phantom load', 'phantom']:
            base_probs['phantom'] += persistence_factor * (1 - base_probs['phantom'])
        elif prev_state in ['light use', 'light']:
            base_probs['light'] += persistence_factor * (1 - base_probs['light'])
        elif prev_state in ['regular use', 'regular']:
            base_probs['regular'] += persistence_factor * (1 - base_probs['regular'])
        
        # ç›®æ¨™ç‹€æ…‹è¶¨å‹¢èª¿æ•´ï¼ˆéš¨æ™‚é–“å¢å¼·ï¼‰
        trend_factor = 0.2 * progress  # æœ€å¤§20%çš„èª¿æ•´
        if target_state in ['phantom load', 'phantom']:
            base_probs['phantom'] += trend_factor
        elif target_state in ['light use', 'light']:
            base_probs['light'] += trend_factor
        elif target_state in ['regular use', 'regular']:
            base_probs['regular'] += trend_factor
        
        # æ­¸ä¸€åŒ–
        total = sum(base_probs.values())
        return {k: v/total for k, v in base_probs.items()}
    
    def save_extended_data(self, extended_df, filename="data/complete_power_data_with_history.csv"):
        """
        ä¿å­˜æ“´å±•æ•¸æ“šä¸¦èˆ‡åŸå§‹æ•¸æ“šåˆä½µ
        """
        print("ğŸ”— åˆä½µæ“´å±•æ•¸æ“šèˆ‡åŸå§‹æ•¸æ“š...")
        
        # ç¢ºä¿åŸå§‹æ•¸æ“šæœ‰å¿…è¦çš„æ¬„ä½
        original_copy = self.original_data.copy()
        if 'power_state' not in original_copy.columns:
            original_copy = self._generate_missing_columns(original_copy)
        
        # åˆä½µæ•¸æ“šï¼ˆæ“´å±•æ•¸æ“šåœ¨å‰ï¼ŒåŸå§‹æ•¸æ“šåœ¨å¾Œï¼‰
        combined_df = pd.concat([extended_df, original_copy], ignore_index=True)
        combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)
        
        # é‡æ–°è¨ˆç®—æ™‚é–“å·®ï¼ˆç¢ºä¿é€£æ¥è™•æ­£ç¢ºï¼‰
        combined_df['time_diff_seconds'] = self._calculate_time_diff(combined_df)
        
        print(f"âœ… åˆä½µå®Œæˆï¼šæ“´å±•æ•¸æ“š {len(extended_df)} ç­† + åŸå§‹æ•¸æ“š {len(self.original_data)} ç­† = ç¸½è¨ˆ {len(combined_df)} ç­†")
        
        # ç¢ºä¿dataç›®éŒ„å­˜åœ¨
        import os
        os.makedirs('data', exist_ok=True)
        
        # ä¿å­˜æª”æ¡ˆ
        combined_df.to_csv(filename, index=False)
        print(f"\nğŸ’¾ å®Œæ•´æ•¸æ“šå·²ä¿å­˜åˆ°ï¼š{filename}")
        
        # é¡¯ç¤ºè©³ç´°çµ±è¨ˆ
        self._print_comprehensive_statistics(combined_df)
        
        return filename
    
    def _print_comprehensive_statistics(self, df):
        """
        é¡¯ç¤ºcomprehensiveçµ±è¨ˆä¿¡æ¯
        """
        print("\n" + "="*80)
        print("ğŸ“Š æ“´å±•æ•¸æ“šçµ±è¨ˆå ±å‘Š")
        print("="*80)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“… æ™‚é–“ç¯„åœï¼š{df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
        print(f"ğŸ“ ç¸½è¨˜éŒ„æ•¸ï¼š{len(df):,}")
        print(f"â±ï¸  æ™‚é–“è·¨åº¦ï¼š{(df['timestamp'].max() - df['timestamp'].min()).days} å¤©")
        
        # åŠŸç‡çµ±è¨ˆ
        print(f"\nâš¡ åŠŸç‡çµ±è¨ˆï¼š")
        print(f"   å¹³å‡åŠŸç‡ï¼š{df['power'].mean():.1f}W")
        print(f"   æœ€å°åŠŸç‡ï¼š{df['power'].min():.1f}W")
        print(f"   æœ€å¤§åŠŸç‡ï¼š{df['power'].max():.1f}W")
        print(f"   æ¨™æº–å·®ï¼š{df['power'].std():.1f}W")
        
        # ç‹€æ…‹åˆ†ä½ˆ
        print(f"\nğŸ”‹ ä½¿ç”¨ç‹€æ…‹åˆ†ä½ˆï¼š")
        state_counts = df['power_state'].value_counts()
        for state, count in state_counts.items():
            percentage = count / len(df) * 100
            print(f"   {state}: {count:,} ç­† ({percentage:.1f}%)")
        
        # æ™‚é–“åˆ†ä½ˆ
        print(f"\nğŸ“… æ™‚é–“åˆ†ä½ˆï¼š")
        df_copy = df.copy()
        df_copy['weekday'] = df_copy['timestamp'].dt.weekday
        weekday_count = (df_copy['weekday'] < 5).sum()
        weekend_count = (df_copy['weekday'] >= 5).sum()
        print(f"   å·¥ä½œæ—¥ï¼š{weekday_count:,} ç­† ({weekday_count/len(df)*100:.1f}%)")
        print(f"   é€±æœ«ï¼š{weekend_count:,} ç­† ({weekend_count/len(df)*100:.1f}%)")
        
        # é ä¼°è€—é›»é‡
        print(f"\nğŸ’¡ é ä¼°è€—é›»é‡ï¼š")
        total_kwh = df['power'].sum() * 0.25 / 1000  # 15åˆ†é˜é–“éš”
        daily_kwh = total_kwh / ((df['timestamp'].max() - df['timestamp'].min()).days)
        annual_kwh = daily_kwh * 365
        print(f"   ç¸½è€—é›»é‡ï¼š{total_kwh:.2f} kWh")
        print(f"   æ—¥å‡è€—é›»ï¼š{daily_kwh:.2f} kWh")
        print(f"   å¹´åº¦é ä¼°ï¼š{annual_kwh:.0f} kWh")
        
        # å°æ¯”åŸå§‹æ•¸æ“š
        if hasattr(self, 'original_data') and self.original_data is not None:
            orig_mean = self.original_data['power'].mean()
            orig_phantom_rate = self.original_data.get('is_phantom_load', pd.Series()).mean()
            new_phantom_rate = df['is_phantom_load'].mean()
            
            print(f"\nğŸ”„ èˆ‡åŸå§‹æ•¸æ“šå°æ¯”ï¼š")
            print(f"   åŸå§‹å¹³å‡åŠŸç‡ï¼š{orig_mean:.1f}W â†’ æ“´å±•å¹³å‡åŠŸç‡ï¼š{df['power'].mean():.1f}W")
            if not pd.isna(orig_phantom_rate):
                print(f"   åŸå§‹Phantom Loadç‡ï¼š{orig_phantom_rate:.1%} â†’ æ“´å±•Phantom Loadç‡ï¼š{new_phantom_rate:.1%}")
        
        print("="*80)


# ä½¿ç”¨ç¤ºä¾‹
def main(csv_path):
    """
    ä¸»å‡½æ•¸ - å¾€å‰æ“´å±•æ•¸æ“šåˆ°2å€‹æœˆ
    """
    print("ğŸš€ é›»åŠ›æ•¸æ“šå¾€å‰æ“´å±•å™¨")
    print("="*50)
    
    # åˆå§‹åŒ–æ“´å±•å™¨
    expander = PowerDataExpander(csv_path)
    
    # åˆ†ææ¨¡å¼
    expander.analyze_patterns()
    
    # å¾€å‰ç”Ÿæˆ8é€±ï¼ˆ2å€‹æœˆï¼‰çš„æ­·å²æ•¸æ“š
    extended_data = expander.generate_extended_data(weeks=8)
    
    # ä¿å­˜æ•¸æ“šï¼ˆè‡ªå‹•åˆä½µåŸå§‹æ•¸æ“šï¼‰
    filename = expander.save_extended_data(extended_data)
    
    print(f"\nğŸ‰ æ“´å±•å®Œæˆï¼è«‹æŸ¥çœ‹ {filename}")
    print("ğŸ’¡ æ‚¨ç¾åœ¨æœ‰å®Œæ•´çš„2å€‹æœˆæ­·å²æ•¸æ“šå¯ä»¥ç”¨æ–¼è¨“ç·´ç³»çµ±")

# æœ€ç°¡å–®çš„ä½¿ç”¨æ–¹å¼
if __name__ == "__main__":
    csv_path = "data/historical_power.csv"  # æ›¿æ›ç‚ºæ‚¨çš„CSVæª”æ¡ˆè·¯å¾‘
    main(csv_path)