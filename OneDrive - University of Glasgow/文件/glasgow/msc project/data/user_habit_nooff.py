# é‡å°ç„¡é—œæ©Ÿå ´æ™¯çš„æ”¹é€²ç‰ˆç”¨æˆ¶ç¿’æ…£æ¨¡çµ„
# é‡æ–°å®šç¾©ä½¿ç”¨ç¿’æ…£ï¼šåŸºæ–¼ä½¿ç”¨å¼·åº¦è½‰æ›è€Œéé–‹é—œæ©Ÿè½‰æ›

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class NoShutdownUserHabitScoreModule:
    """
    å°ˆé–€é‡å°ç„¡é—œæ©Ÿå ´æ™¯çš„ç”¨æˆ¶ç¿’æ…£åˆ†æ•¸æ¨¡çµ„
    é‡æ–°å®šç¾©ä½¿ç”¨ç¿’æ…£ï¼š
    - ä½¿ç”¨å¼·åº¦æ¨¡å¼ï¼šphantom load -> light use -> regular use
    - æ´»èºåº¦è½‰æ›ï¼šéæ´»èº (phantom) -> æ´»èº (light/regular)
    - æ™‚é–“æ¨¡å¼åˆ†æï¼šä¸åŒæ™‚æ®µçš„ä½¿ç”¨å¼·åº¦åå¥½
    """

    def __init__(self):
        self.time_slots = 96
        self.intensity_transition_data = None
        self.usage_intensity_matrix = {}
        self.usage_consistency_matrix = {}
        self.time_preference_matrix = {}
        self.habit_rules = []
        self.membership_parameters = {}
        self.data_quality_report = {}

    def validate_data_quality(self, df):
        """æ•¸æ“šè³ªé‡é©—è­‰"""
        print("==== Data Quality Validation ====")
        issues = []
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = ['timestamp', 'power_state', 'is_phantom_load', 'is_light_use', 'is_regular_use']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            issues.append(f"Missing columns: {missing_columns}")
        
        # æª¢æŸ¥æ•¸æ“šç¯„åœ
        if len(df) < 100:
            issues.append(f"Insufficient data: only {len(df)} records")
        
        # æª¢æŸ¥ç‹€æ…‹åˆ†ä½ˆï¼ˆé‡å°ç„¡é—œæ©Ÿå ´æ™¯ï¼‰
        if 'power_state' in df.columns:
            state_counts = df['power_state'].value_counts()
            phantom_ratio = state_counts.get('phantom load', 0) / len(df)
            if phantom_ratio > 0.95:
                issues.append("Over 95% phantom load - limited usage pattern diversity")
            elif phantom_ratio < 0.1:
                issues.append("Less than 10% phantom load - unusual power pattern")
        
        self.data_quality_report = {
            'total_records': len(df),
            'issues': issues,
            'quality_score': max(0, 1.0 - len(issues) * 0.2)
        }
        
        print(f"Data quality score: {self.data_quality_report['quality_score']:.2f}")
        if issues:
            print("Issues found:")
            for issue in issues:
                print(f"  - {issue}")
        else:
            print("âœ“ No major data quality issues found")
        
        return issues

    def preprocess_data_enhanced(self, df):
        """å¢å¼·çš„æ•¸æ“šé è™•ç†"""
        print("==== Enhanced Data Preprocessing ====")
        
        df = df.copy()
        
        # è™•ç†ç¼ºå¤±å€¼
        original_nan_count = df.isnull().sum().sum()
        if original_nan_count > 0:
            print(f"Handling {original_nan_count} missing values...")
            df = df.fillna(method='ffill').fillna(method='bfill')
        
        # è™•ç†æ™‚é–“å·®ç•°å¸¸å€¼
        if 'time_diff_seconds' in df.columns:
            Q1 = df['time_diff_seconds'].quantile(0.25)
            Q3 = df['time_diff_seconds'].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = max(0, Q1 - 1.5 * IQR)
            upper_bound = Q3 + 1.5 * IQR
            
            outliers_mask = (df['time_diff_seconds'] < lower_bound) | (df['time_diff_seconds'] > upper_bound)
            outliers_count = outliers_mask.sum()
            
            if outliers_count > 0:
                print(f"Handling {outliers_count} time_diff outliers...")
                df.loc[outliers_mask, 'time_diff_seconds'] = df['time_diff_seconds'].median()
        
        print(f"âœ“ Preprocessing completed. Final dataset: {len(df)} records")
        return df

    def load_data(self, file_path):
        print("==== Loading Usage Data for User Habit Score ====")
        
        try:
            df = pd.read_csv(file_path)
            
            # æ•¸æ“šè³ªé‡é©—è­‰
            quality_issues = self.validate_data_quality(df)
            if len(quality_issues) > 3:
                print("âš ï¸  Warning: Multiple data quality issues detected. Results may be unreliable.")
            
            # å¢å¼·é è™•ç†
            df = self.preprocess_data_enhanced(df)
            
            # æ·»åŠ æ™‚é–“ç‰¹å¾µ
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df['hour'] = df['timestamp'].dt.hour
            df['minute'] = df['timestamp'].dt.minute
            df['weekday'] = df['timestamp'].dt.weekday
            df['is_weekend'] = df['weekday'] >= 5
            df['day_type'] = df['is_weekend'].map({True: 'weekend', False: 'weekday'})
            df['time_slot'] = df['hour'] * 4 + df['minute'] // 15
            
            # é‡æ–°å®šç¾©æ´»èºç‹€æ…‹ï¼ˆé‡å°ç„¡é—œæ©Ÿå ´æ™¯ï¼‰
            df['is_active'] = (df.get('is_light_use', False) | df.get('is_regular_use', False))
            df['is_inactive'] = df.get('is_phantom_load', True)
            
            # å®šç¾©ä½¿ç”¨å¼·åº¦ç­‰ç´š
            df['intensity_level'] = 0  # é»˜èªç‚º0
            df.loc[df.get('is_phantom_load', False), 'intensity_level'] = 1  # phantom load
            df.loc[df.get('is_light_use', False), 'intensity_level'] = 2     # light use  
            df.loc[df.get('is_regular_use', False), 'intensity_level'] = 3   # regular use
            
            print(f"âœ“ Loaded usage data: {len(df)} records")
            print(f"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")
            print(f"Weekdays: {sum(~df['is_weekend'])}, Weekends: {sum(df['is_weekend'])}")
            
            return df
            
        except Exception as e:
            print(f"âŒ Error loading data: {e}")
            return None

    def triangular_membership(self, x, a, b, c):
        """ä¸‰è§’éš¸å±¬å‡½æ•¸"""
        if isinstance(x, (list, np.ndarray)):
            x = np.array(x)
            return np.array([self.triangular_membership(xi, a, b, c) for xi in x])
        
        if np.isnan(x) or np.isnan(a) or np.isnan(b) or np.isnan(c):
            return 0.0
        
        if a == b == c:
            return 1.0 if x == a else 0.0
        
        if a > b or b > c:
            return 0.0
        
        try:
            if x <= a or x >= c:
                return 0.0
            elif x == b:
                return 1.0
            elif a < x < b:
                return (x - a) / (b - a) if (b - a) > 0 else 0.0
            else:
                return (c - x) / (c - b) if (c - b) > 0 else 0.0
        except:
            return 0.0

    def analyze_intensity_transitions(self, df):
        """åˆ†æä½¿ç”¨å¼·åº¦è½‰æ›æ¨¡å¼"""
        print("==== State Transitions Analysis ====")
        
        print("Available state columns:")
        state_cols = ['power_state', 'is_phantom_load', 'is_light_use', 'is_regular_use']
        for col in state_cols:
            if col in df.columns:
                print(f"  {col}: {df[col].value_counts().to_dict()}")
        
        df_sorted = df.sort_values('timestamp').reset_index(drop=True)
        
        # åˆ†æå¼·åº¦è½‰æ›è€Œéé–‹é—œæ©Ÿè½‰æ›
        df_sorted['prev_intensity'] = df_sorted['intensity_level'].shift(1)
        df_sorted['prev_active'] = df_sorted['is_active'].shift(1)
        
        # æ‰¾å‡ºå¾éæ´»èºåˆ°æ´»èºçš„è½‰æ›
        activation_events = df_sorted[
            (df_sorted['prev_active'] == False) & 
            (df_sorted['is_active'] == True)
        ].copy()
        
        # æ‰¾å‡ºå¾æ´»èºåˆ°éæ´»èºçš„è½‰æ›
        deactivation_events = df_sorted[
            (df_sorted['prev_active'] == True) & 
            (df_sorted['is_active'] == False)
        ].copy()
        
        print(f"\nTransition Analysis:")
        print(f"Activation events (phantom -> active): {len(activation_events)}")
        print(f"Deactivation events (active -> phantom): {len(deactivation_events)}")
        
        # å»ºç«‹è½‰æ›è¨˜éŒ„
        transition_records = []
        
        for idx, activation in activation_events.iterrows():
            activation_time = activation['timestamp']
            activation_slot = activation['time_slot']
            activation_day_type = activation['day_type']
            
            # æ‰¾åˆ°ä¸‹ä¸€å€‹éæ´»èºäº‹ä»¶
            next_deactivation = deactivation_events[
                deactivation_events['timestamp'] > activation_time
            ]
            
            if len(next_deactivation) > 0:
                deactivation_time = next_deactivation.iloc[0]['timestamp']
                active_duration = (deactivation_time - activation_time).total_seconds() / 60.0
                
                # éæ¿¾åˆç†çš„æŒçºŒæ™‚é–“
                if 1 <= active_duration <= 1440:  # 1åˆ†é˜åˆ°24å°æ™‚
                    transition_records.append({
                        'activation_time': activation_time,
                        'deactivation_time': deactivation_time,
                        'active_duration': active_duration,
                        'time_slot': activation_slot,
                        'day_type': activation_day_type,
                        'activation_hour': activation_time.hour,
                        'activation_intensity': activation['intensity_level']
                    })
        
        self.intensity_transition_data = pd.DataFrame(transition_records)
        
        print(f"\nCreated {len(self.intensity_transition_data)} valid transition records")
        
        if len(self.intensity_transition_data) > 0:
            durations = self.intensity_transition_data['active_duration']
            print(f"Active duration statistics:")
            print(f"  Min: {durations.min():.1f} minutes")
            print(f"  Max: {durations.max():.1f} minutes")
            print(f"  Mean: {durations.mean():.1f} minutes")
            print(f"  Median: {durations.median():.1f} minutes")
        else:
            print("âš ï¸  No valid transitions found - using fallback probability calculation")
        
        return self.intensity_transition_data

    def calculate_usage_intensity(self, df):
        """è¨ˆç®—ä½¿ç”¨å¼·åº¦åå¥½"""
        print("==== Calculating Usage Intensity ====")
        
        valid_entries = 0
        
        for day_type in ['weekday', 'weekend']:
            for time_slot in range(self.time_slots):
                mask = (df['day_type'] == day_type) & (df['time_slot'] == time_slot)
                slot_data = df[mask]
                
                if len(slot_data) < 1:
                    # ä½¿ç”¨é»˜èªå€¼
                    hour = time_slot // 4
                    if day_type == 'weekday':
                        if 7 <= hour <= 9 or 18 <= hour <= 22:  # å·¥ä½œæ—¥é«˜å³°æ™‚æ®µ
                            phantom_prob, light_prob, regular_prob = 0.4, 0.4, 0.2
                        elif 10 <= hour <= 17:  # å·¥ä½œæ™‚é–“
                            phantom_prob, light_prob, regular_prob = 0.7, 0.2, 0.1
                        else:  # å…¶ä»–æ™‚é–“
                            phantom_prob, light_prob, regular_prob = 0.8, 0.15, 0.05
                    else:  # weekend
                        if 9 <= hour <= 22:  # é€±æœ«ç™½å¤©
                            phantom_prob, light_prob, regular_prob = 0.5, 0.3, 0.2
                        else:  # é€±æœ«å¤œé–“
                            phantom_prob, light_prob, regular_prob = 0.85, 0.1, 0.05
                    
                    self.usage_intensity_matrix[(day_type, time_slot)] = {
                        'phantom_prob': phantom_prob,
                        'light_prob': light_prob,
                        'regular_prob': regular_prob,
                        'avg_intensity': phantom_prob * 1 + light_prob * 2 + regular_prob * 3,
                        'sample_size': 0
                    }
                    continue
                
                try:
                    # è¨ˆç®—å„å¼·åº¦ç­‰ç´šçš„æ¦‚ç‡
                    total_records = len(slot_data)
                    phantom_count = len(slot_data[slot_data['intensity_level'] == 1])
                    light_count = len(slot_data[slot_data['intensity_level'] == 2])
                    regular_count = len(slot_data[slot_data['intensity_level'] == 3])
                    
                    phantom_prob = phantom_count / total_records
                    light_prob = light_count / total_records
                    regular_prob = regular_count / total_records
                    
                    # è¨ˆç®—å¹³å‡å¼·åº¦
                    avg_intensity = slot_data['intensity_level'].mean()
                    
                    self.usage_intensity_matrix[(day_type, time_slot)] = {
                        'phantom_prob': phantom_prob,
                        'light_prob': light_prob,
                        'regular_prob': regular_prob,
                        'avg_intensity': avg_intensity,
                        'sample_size': total_records
                    }
                    valid_entries += 1
                    
                except Exception as e:
                    print(f"âš ï¸  Error calculating intensity for {day_type} slot {time_slot}: {e}")
                    self.usage_intensity_matrix[(day_type, time_slot)] = {
                        'phantom_prob': 0.7,
                        'light_prob': 0.2,
                        'regular_prob': 0.1,
                        'avg_intensity': 1.4,
                        'sample_size': len(slot_data)
                    }
        
        print(f"âœ“ Calculated usage intensity for {valid_entries} time slots")
        return self.usage_intensity_matrix

    def calculate_usage_consistency(self, df):
        """è¨ˆç®—ä½¿ç”¨ä¸€è‡´æ€§"""
        print("==== Calculating Usage Stability ====")
        
        valid_entries = 0
        
        for day_type in ['weekday', 'weekend']:
            for time_slot in range(self.time_slots):
                mask = (df['day_type'] == day_type) & (df['time_slot'] == time_slot)
                slot_data = df[mask]
                
                if len(slot_data) < 2:
                    self.usage_consistency_matrix[(day_type, time_slot)] = {
                        'intensity_consistency': 0.5,
                        'temporal_consistency': 0.5,
                        'overall_consistency': 0.5,
                        'sample_size': len(slot_data)
                    }
                    continue
                
                try:
                    # è¨ˆç®—å¼·åº¦ä¸€è‡´æ€§
                    intensity_std = slot_data['intensity_level'].std()
                    max_intensity_std = 1.0  # å¼·åº¦ç¯„åœ1-3ï¼Œç†è«–æœ€å¤§æ¨™æº–å·®ç´„ç‚º1
                    intensity_consistency = max(0, 1 - intensity_std / max_intensity_std)
                    
                    # è¨ˆç®—æ™‚é–“ä¸€è‡´æ€§ï¼ˆæ¯æ—¥è©²æ™‚æ®µçš„ä½¿ç”¨æ¨¡å¼ï¼‰
                    daily_usage = slot_data.groupby(slot_data['timestamp'].dt.date).agg({
                        'intensity_level': 'mean',
                        'is_active': 'max'
                    })
                    
                    if len(daily_usage) > 1:
                        temporal_std = daily_usage['intensity_level'].std()
                        temporal_consistency = max(0, 1 - temporal_std / max_intensity_std)
                    else:
                        temporal_consistency = 0.5
                    
                    # ç¶œåˆä¸€è‡´æ€§
                    overall_consistency = (intensity_consistency + temporal_consistency) / 2
                    
                    self.usage_consistency_matrix[(day_type, time_slot)] = {
                        'intensity_consistency': intensity_consistency,
                        'temporal_consistency': temporal_consistency,
                        'overall_consistency': overall_consistency,
                        'sample_size': len(slot_data)
                    }
                    valid_entries += 1
                    
                except Exception as e:
                    print(f"âš ï¸  Error calculating consistency for {day_type} slot {time_slot}: {e}")
                    self.usage_consistency_matrix[(day_type, time_slot)] = {
                        'intensity_consistency': 0.4,
                        'temporal_consistency': 0.4,
                        'overall_consistency': 0.4,
                        'sample_size': len(slot_data)
                    }
        
        print(f"âœ“ Calculated stability for {valid_entries} time slots")
        return self.usage_consistency_matrix

    def calculate_time_preference(self, df):
        """è¨ˆç®—æ™‚é–“åå¥½"""
        print("==== Calculating Time Factor ====")
        
        valid_entries = 0
        
        for day_type in ['weekday', 'weekend']:
            for time_slot in range(self.time_slots):
                mask = (df['day_type'] == day_type) & (df['time_slot'] == time_slot)
                slot_data = df[mask]
                
                if len(slot_data) < 1:
                    hour = time_slot // 4
                    if day_type == 'weekday':
                        if 7 <= hour <= 9 or 18 <= hour <= 22:
                            preference_score = 0.8  # é«˜åå¥½æ™‚æ®µ
                        elif 10 <= hour <= 17:
                            preference_score = 0.4  # ä¸­ç­‰åå¥½
                        else:
                            preference_score = 0.2  # ä½åå¥½
                    else:
                        if 9 <= hour <= 22:
                            preference_score = 0.6
                        else:
                            preference_score = 0.3
                    
                    self.time_preference_matrix[(day_type, time_slot)] = {
                        'activation_rate': 0.0,
                        'avg_intensity': 1.0,
                        'weighted_preference': preference_score,
                        'sample_size': 0
                    }
                    continue
                
                try:
                    total_records = len(slot_data)
                    active_records = len(slot_data[slot_data['is_active'] == True])
                    activation_rate = active_records / total_records if total_records > 0 else 0
                    
                    # è¨ˆç®—åŠ æ¬Šå¼·åº¦åå¥½
                    avg_intensity = slot_data['intensity_level'].mean()
                    
                    # çµåˆæ¿€æ´»ç‡å’Œå¼·åº¦è¨ˆç®—æ•´é«”åå¥½
                    weighted_preference = (activation_rate * 0.6 + (avg_intensity - 1) / 2 * 0.4)
                    weighted_preference = max(0.0, min(1.0, weighted_preference))
                    
                    self.time_preference_matrix[(day_type, time_slot)] = {
                        'activation_rate': activation_rate,
                        'avg_intensity': avg_intensity,
                        'weighted_preference': weighted_preference,
                        'sample_size': total_records
                    }
                    valid_entries += 1
                    
                except Exception as e:
                    print(f"âš ï¸  Error calculating time preference for {day_type} slot {time_slot}: {e}")
                    self.time_preference_matrix[(day_type, time_slot)] = {
                        'activation_rate': 0.2,
                        'avg_intensity': 1.5,
                        'weighted_preference': 0.3,
                        'sample_size': len(slot_data)
                    }
        
        print(f"âœ“ Calculated time factor for {valid_entries} time slots")
        return self.time_preference_matrix

    def calculate_membership_parameters(self):
        """è¨ˆç®—çµ±è¨ˆéš¸å±¬åƒæ•¸"""
        print("==== Calculating Statistical Membership Parameters ====")
        
        self.membership_parameters = {
            'usage_intensity': {},
            'consistency': {},
            'time_preference': {}
        }
        
        # æ”¶é›†ä½¿ç”¨å¼·åº¦æ•¸æ“š
        intensity_values = []
        for key in self.usage_intensity_matrix:
            data = self.usage_intensity_matrix[key]
            if 'avg_intensity' in data and not np.isnan(data['avg_intensity']):
                intensity_values.append(data['avg_intensity'])
        
        if intensity_values:
            intensity_values = np.array(intensity_values)
            self.membership_parameters['usage_intensity'] = {
                'p0': float(np.min(intensity_values)),
                'p25': float(np.percentile(intensity_values, 25)),
                'p50': float(np.percentile(intensity_values, 50)),
                'p75': float(np.percentile(intensity_values, 75)),
                'p100': float(np.max(intensity_values))
            }
            print(f"Usage Intensity Statistics (n={len(intensity_values)}): âœ“")
        else:
            print("âš ï¸  No valid intensity data, using defaults")
            self.membership_parameters['usage_intensity'] = {
                'p0': 1.0, 'p25': 1.25, 'p50': 1.5, 'p75': 2.0, 'p100': 3.0
            }
        
        # æ”¶é›†ä¸€è‡´æ€§æ•¸æ“š
        consistency_values = []
        for key in self.usage_consistency_matrix:
            data = self.usage_consistency_matrix[key]
            if 'overall_consistency' in data and not np.isnan(data['overall_consistency']):
                consistency_values.append(data['overall_consistency'])
        
        if consistency_values:
            consistency_values = np.array(consistency_values)
            self.membership_parameters['consistency'] = {
                'p0': float(np.min(consistency_values)),
                'p25': float(np.percentile(consistency_values, 25)),
                'p50': float(np.percentile(consistency_values, 50)),
                'p75': float(np.percentile(consistency_values, 75)),
                'p100': float(np.max(consistency_values))
            }
            print(f"Stability Statistics (n={len(consistency_values)}): âœ“")
        else:
            print("âš ï¸  No valid consistency data, using defaults")
            self.membership_parameters['consistency'] = {
                'p0': 0.0, 'p25': 0.25, 'p50': 0.5, 'p75': 0.75, 'p100': 1.0
            }
        
        # æ”¶é›†æ™‚é–“åå¥½æ•¸æ“š
        preference_values = []
        for key in self.time_preference_matrix:
            data = self.time_preference_matrix[key]
            if 'weighted_preference' in data and not np.isnan(data['weighted_preference']):
                preference_values.append(data['weighted_preference'])
        
        if preference_values:
            preference_values = np.array(preference_values)
            self.membership_parameters['time_preference'] = {
                'p0': float(np.min(preference_values)),
                'p25': float(np.percentile(preference_values, 25)),
                'p50': float(np.percentile(preference_values, 50)),
                'p75': float(np.percentile(preference_values, 75)),
                'p100': float(np.max(preference_values))
            }
            print(f"Time Factor Statistics (n={len(preference_values)}): âœ“")
        else:
            print("âš ï¸  No valid time preference data, using defaults")
            self.membership_parameters['time_preference'] = {
                'p0': 0.0, 'p25': 0.25, 'p50': 0.5, 'p75': 0.75, 'p100': 1.0
            }
        
        return self.membership_parameters

    def define_habit_rules(self):
        """å®šç¾©ä½¿ç”¨ç¿’æ…£æ¨¡ç³Šè¦å‰‡ï¼ˆé‡å°ç„¡é—œæ©Ÿå ´æ™¯ï¼‰"""
        print("==== Defining User Habit Rules ====")
        
        # è¦å‰‡æ ¼å¼: (ä½¿ç”¨å¼·åº¦, ä¸€è‡´æ€§, æ™‚é–“åå¥½, è¼¸å‡ºç¿’æ…£ç­‰ç´š, æ¬Šé‡)
        self.habit_rules = [
            # é«˜ç¿’æ…£åˆ†æ•¸è¦å‰‡ï¼šå¼·çƒˆåå¥½è©²æ™‚æ®µä½¿ç”¨
            ('high', 'high', 'high', 'high', 1.0),      # é«˜å¼·åº¦+é«˜ä¸€è‡´æ€§+é«˜åå¥½
            ('high', 'high', 'medium', 'high', 0.9),    # é«˜å¼·åº¦+é«˜ä¸€è‡´æ€§+ä¸­åå¥½
            ('high', 'medium', 'high', 'high', 0.85),   # é«˜å¼·åº¦+ä¸­ä¸€è‡´æ€§+é«˜åå¥½
            ('medium', 'high', 'high', 'high', 0.8),    # ä¸­å¼·åº¦+é«˜ä¸€è‡´æ€§+é«˜åå¥½
            
            # ä¸­é«˜ç¿’æ…£åˆ†æ•¸è¦å‰‡
            ('high', 'low', 'high', 'medium', 0.75),    # é«˜å¼·åº¦ä½†ä½ä¸€è‡´æ€§
            ('high', 'medium', 'medium', 'medium', 0.7), # é«˜å¼·åº¦+ä¸­ç­‰å…¶ä»–å› ç´ 
            ('medium', 'high', 'medium', 'medium', 0.75), # ä¸­å¼·åº¦+é«˜ä¸€è‡´æ€§
            ('medium', 'medium', 'high', 'medium', 0.65), # ä¸­ç­‰æ¢ä»¶çµ„åˆ
            
            # ä¸­ç­‰ç¿’æ…£åˆ†æ•¸è¦å‰‡
            ('high', 'high', 'low', 'medium', 0.6),     # é«˜å¼·åº¦ä½†ä½åå¥½æ™‚æ®µ
            ('low', 'high', 'high', 'medium', 0.55),    # ä½å¼·åº¦ä½†é«˜ä¸€è‡´æ€§+é«˜åå¥½
            ('medium', 'low', 'high', 'medium', 0.5),   # ä¸­å¼·åº¦+ä½ä¸€è‡´æ€§+é«˜åå¥½
            ('medium', 'medium', 'medium', 'medium', 0.55), # å…¨ä¸­ç­‰æ¢ä»¶
            
            # ä½ç¿’æ…£åˆ†æ•¸è¦å‰‡ï¼šå¯ä»¥é—œæ©Ÿç¯€èƒ½
            ('low', 'high', 'medium', 'low', 0.6),      # ä½å¼·åº¦+é«˜ä¸€è‡´æ€§
            ('low', 'medium', 'high', 'low', 0.5),      # ä½å¼·åº¦+ä¸­ä¸€è‡´æ€§+é«˜åå¥½
            ('medium', 'low', 'medium', 'low', 0.5),    # ä¸­å¼·åº¦+ä½ä¸€è‡´æ€§
            ('high', 'low', 'low', 'low', 0.45),        # é«˜å¼·åº¦ä½†ä½ä¸€è‡´æ€§+ä½åå¥½
            
            # å¾ˆä½ç¿’æ…£åˆ†æ•¸è¦å‰‡ï¼šå¼·çƒˆå»ºè­°é—œæ©Ÿ
            ('low', 'high', 'low', 'low', 0.8),         # ä½å¼·åº¦+ä½åå¥½ä½†ä¸€è‡´
            ('low', 'medium', 'low', 'low', 0.75),      # ä½å¼·åº¦+ä½åå¥½
            ('medium', 'low', 'low', 'low', 0.7),       # ä¸­å¼·åº¦ä½†å…¶ä»–éƒ½ä½
            ('low', 'low', 'medium', 'low', 0.6),       # ä½æ¢ä»¶çµ„åˆ
            ('low', 'low', 'low', 'low', 0.9),          # å…¨ä½æ¢ä»¶
        ]
        
        print(f"âœ“ Defined {len(self.habit_rules)} habit rules")
        return self.habit_rules

    def calculate_fuzzy_memberships(self, timestamp):
        """è¨ˆç®—æŒ‡å®šæ™‚é–“é»çš„æ¨¡ç³Šéš¸å±¬åº¦"""
        hour = timestamp.hour
        minute = timestamp.minute
        is_weekend = timestamp.weekday() >= 5
        day_type = 'weekend' if is_weekend else 'weekday'
        time_slot = hour * 4 + minute // 15
        
        result = {
            'day_type': day_type,
            'time_slot': time_slot,
            'hour': hour,
            'minute': minute
        }
        
        # ç²å–ä½¿ç”¨å¼·åº¦éš¸å±¬åº¦
        if (day_type, time_slot) in self.usage_intensity_matrix:
            intensity_data = self.usage_intensity_matrix[(day_type, time_slot)]
            avg_intensity = intensity_data.get('avg_intensity', 1.5)
            
            intensity_params = self.membership_parameters['usage_intensity']
            result['intensity_low'] = self.triangular_membership(
                avg_intensity, intensity_params['p0'], intensity_params['p25'], intensity_params['p50']
            )
            result['intensity_medium'] = self.triangular_membership(
                avg_intensity, intensity_params['p25'], intensity_params['p50'], intensity_params['p75']
            )
            result['intensity_high'] = self.triangular_membership(
                avg_intensity, intensity_params['p50'], intensity_params['p75'], intensity_params['p100']
            )
            result['avg_intensity'] = avg_intensity
        else:
            result.update({
                'intensity_low': 0.7, 'intensity_medium': 0.3, 'intensity_high': 0.0,
                'avg_intensity': 1.2
            })
        
        # ç²å–ä¸€è‡´æ€§éš¸å±¬åº¦
        if (day_type, time_slot) in self.usage_consistency_matrix:
            consistency_data = self.usage_consistency_matrix[(day_type, time_slot)]
            overall_consistency = consistency_data.get('overall_consistency', 0.5)
            
            consistency_params = self.membership_parameters['consistency']
            result['consistency_low'] = self.triangular_membership(
                overall_consistency, consistency_params['p0'], consistency_params['p25'], consistency_params['p50']
            )
            result['consistency_medium'] = self.triangular_membership(
                overall_consistency, consistency_params['p25'], consistency_params['p50'], consistency_params['p75']
            )
            result['consistency_high'] = self.triangular_membership(
                overall_consistency, consistency_params['p50'], consistency_params['p75'], consistency_params['p100']
            )
            result['consistency'] = overall_consistency
        else:
            result.update({
                'consistency_low': 0.6, 'consistency_medium': 0.4, 'consistency_high': 0.0,
                'consistency': 0.4
            })
        
        # ç²å–æ™‚é–“åå¥½éš¸å±¬åº¦
        if (day_type, time_slot) in self.time_preference_matrix:
            preference_data = self.time_preference_matrix[(day_type, time_slot)]
            weighted_preference = preference_data.get('weighted_preference', 0.3)
            
            preference_params = self.membership_parameters['time_preference']
            result['preference_low'] = self.triangular_membership(
                weighted_preference, preference_params['p0'], preference_params['p25'], preference_params['p50']
            )
            result['preference_medium'] = self.triangular_membership(
                weighted_preference, preference_params['p25'], preference_params['p50'], preference_params['p75']
            )
            result['preference_high'] = self.triangular_membership(
                weighted_preference, preference_params['p50'], preference_params['p75'], preference_params['p100']
            )
            result['time_preference'] = weighted_preference
        else:
            result.update({
                'preference_low': 0.6, 'preference_medium': 0.4, 'preference_high': 0.0,
                'time_preference': 0.3
            })
        
        return result

    def calculate_habit_score(self, timestamp):
        """è¨ˆç®—ç¿’æ…£åˆ†æ•¸ï¼ˆé‡å°ç„¡é—œæ©Ÿå ´æ™¯ï¼‰"""
        try:
            memberships = self.calculate_fuzzy_memberships(timestamp)
            
            low_activation = 0.0
            medium_activation = 0.0
            high_activation = 0.0
            valid_rules = 0
            
            for rule in self.habit_rules:
                intensity_level, consistency_level, preference_level, output_level, weight = rule
                
                # ç²å–éš¸å±¬åº¦
                intensity_membership = memberships.get(f'intensity_{intensity_level}', 0.0)
                consistency_membership = memberships.get(f'consistency_{consistency_level}', 0.0)
                preference_membership = memberships.get(f'preference_{preference_level}', 0.0)
                
                # æª¢æŸ¥æœ‰æ•ˆæ€§
                if any(np.isnan([intensity_membership, consistency_membership, preference_membership])):
                    continue
                
                # ä½¿ç”¨åŠ æ¬Šå¹¾ä½•å¹³å‡
                if all(m >= 0 for m in [intensity_membership, consistency_membership, preference_membership]):
                    memberships_adj = [max(0.01, m) for m in [intensity_membership, consistency_membership, preference_membership]]
                    activation = (memberships_adj[0] * memberships_adj[1] * memberships_adj[2]) ** (1/3) * weight
                    
                    # ç´¯ç©æ¿€æ´»
                    if output_level == 'low':
                        low_activation += activation
                    elif output_level == 'medium':
                        medium_activation += activation
                    elif output_level == 'high':
                        high_activation += activation
                    
                    valid_rules += 1
            
            # é™åˆ¶æ¿€æ´»å¼·åº¦
            low_activation = min(low_activation, 1.0)
            medium_activation = min(medium_activation, 1.0)
            high_activation = min(high_activation, 1.0)
            
            # è¨ˆç®—æœ€çµ‚åˆ†æ•¸
            total_activation = low_activation + medium_activation + high_activation
            
            if total_activation > 0 and valid_rules > 0:
                # ä½¿ç”¨åŠ æ¬Šé‡å¿ƒæ³•
                habit_score = (
                    low_activation * 0.2 +
                    medium_activation * 0.5 +
                    high_activation * 0.8
                ) / total_activation
                
                # åŸºæ–¼å¯¦éš›æ•¸æ“šçš„å¾®èª¿
                avg_intensity = memberships.get('avg_intensity', 1.5)
                consistency = memberships.get('consistency', 0.5)
                time_preference = memberships.get('time_preference', 0.3)
                
                # æ­¸ä¸€åŒ–å¾Œçš„èª¿æ•´
                normalized_intensity = (avg_intensity - 1) / 2  # å°‡1-3æ˜ å°„åˆ°0-1
                data_adjustment = (normalized_intensity + consistency + time_preference - 1.5) * 0.05
                habit_score += data_adjustment
                
                confidence = min(1.0, total_activation * valid_rules / len(self.habit_rules))
            else:
                habit_score = 0.3
                confidence = 0.1
            
            # ç¢ºä¿åˆ†æ•¸åœ¨åˆç†ç¯„åœå…§
            habit_score = max(0.05, min(0.95, habit_score))
            
            return {
                'habit_score': habit_score,
                'low_activation': low_activation,
                'medium_activation': medium_activation,
                'high_activation': high_activation,
                'memberships': memberships,
                'confidence': confidence,
                'valid_rules': valid_rules
            }
            
        except Exception as e:
            print(f"âš ï¸  Error calculating habit score: {e}")
            return {
                'habit_score': 0.3,
                'low_activation': 0.0,
                'medium_activation': 0.5,
                'high_activation': 0.0,
                'memberships': {},
                'confidence': 0.1,
                'valid_rules': 0
            }

    def plot_triangular_membership_functions(self):
        """ç¹ªè£½ä¸‰è§’éš¸å±¬å‡½æ•¸åœ–"""
        if not hasattr(self, 'membership_parameters') or not self.membership_parameters:
            print("âŒ æ²’æœ‰æ‰¾åˆ° membership_parametersï¼Œè«‹å…ˆé‹è¡Œå®Œæ•´åˆ†æ")
            return
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        fig.suptitle('ä¸‰è§’éš¸å±¬å‡½æ•¸åƒæ•¸è©³æƒ…', fontsize=16, fontweight='bold')
        
        colors = ['red', 'orange', 'green']
        line_styles = ['-', '--', '-.']
        
        # 1. ä½¿ç”¨å¼·åº¦éš¸å±¬å‡½æ•¸
        ax1 = axes[0]
        x_intensity = np.linspace(1, 3, 1000)
        
        if 'usage_intensity' in self.membership_parameters:
            intensity_params = self.membership_parameters['usage_intensity']
            
            if all(key in intensity_params for key in ['p0', 'p25', 'p50', 'p75', 'p100']):
                p0, p25, p50, p75, p100 = [intensity_params[k] for k in ['p0', 'p25', 'p50', 'p75', 'p100']]
                
                intensity_low = np.array([self.triangular_membership(x, p0, p25, p50) for x in x_intensity])
                intensity_medium = np.array([self.triangular_membership(x, p25, p50, p75) for x in x_intensity])
                intensity_high = np.array([self.triangular_membership(x, p50, p75, p100) for x in x_intensity])
                
                ax1.plot(x_intensity, intensity_low, color=colors[0], linewidth=3, 
                        label=f'Low ({p0:.2f}, {p25:.2f}, {p50:.2f})', linestyle=line_styles[0])
                ax1.plot(x_intensity, intensity_medium, color=colors[1], linewidth=3, 
                        label=f'Medium ({p25:.2f}, {p50:.2f}, {p75:.2f})', linestyle=line_styles[1])
                ax1.plot(x_intensity, intensity_high, color=colors[2], linewidth=3, 
                        label=f'High ({p50:.2f}, {p75:.2f}, {p100:.2f})', linestyle=line_styles[2])
                
                ax1.fill_between(x_intensity, 0, intensity_low, alpha=0.2, color=colors[0])
                ax1.fill_between(x_intensity, 0, intensity_medium, alpha=0.2, color=colors[1])
                ax1.fill_between(x_intensity, 0, intensity_high, alpha=0.2, color=colors[2])
        
        ax1.set_xlabel('å¹³å‡ä½¿ç”¨å¼·åº¦ (1=phantom, 2=light, 3=regular)')
        ax1.set_ylabel('éš¸å±¬åº¦')
        ax1.set_title('ä½¿ç”¨å¼·åº¦åå¥½', fontweight='bold')
        ax1.legend(loc='upper right', fontsize=9)
        ax1.grid(True, alpha=0.3)
        ax1.set_xlim(1, 3)
        ax1.set_ylim(0, 1.1)
        
        # 2. ä¸€è‡´æ€§éš¸å±¬å‡½æ•¸
        ax2 = axes[1]
        x_consistency = np.linspace(0, 1, 1000)
        
        if 'consistency' in self.membership_parameters:
            consistency_params = self.membership_parameters['consistency']
            
            if all(key in consistency_params for key in ['p0', 'p25', 'p50', 'p75', 'p100']):
                p0, p25, p50, p75, p100 = [consistency_params[k] for k in ['p0', 'p25', 'p50', 'p75', 'p100']]
                
                consistency_low = np.array([self.triangular_membership(x, p0, p25, p50) for x in x_consistency])
                consistency_medium = np.array([self.triangular_membership(x, p25, p50, p75) for x in x_consistency])
                consistency_high = np.array([self.triangular_membership(x, p50, p75, p100) for x in x_consistency])
                
                ax2.plot(x_consistency, consistency_low, color=colors[0], linewidth=3, 
                        label=f'Low ({p0:.2f}, {p25:.2f}, {p50:.2f})', linestyle=line_styles[0])
                ax2.plot(x_consistency, consistency_medium, color=colors[1], linewidth=3, 
                        label=f'Medium ({p25:.2f}, {p50:.2f}, {p75:.2f})', linestyle=line_styles[1])
                ax2.plot(x_consistency, consistency_high, color=colors[2], linewidth=3, 
                        label=f'High ({p50:.2f}, {p75:.2f}, {p100:.2f})', linestyle=line_styles[2])
                
                ax2.fill_between(x_consistency, 0, consistency_low, alpha=0.2, color=colors[0])
                ax2.fill_between(x_consistency, 0, consistency_medium, alpha=0.2, color=colors[1])
                ax2.fill_between(x_consistency, 0, consistency_high, alpha=0.2, color=colors[2])
        
        ax2.set_xlabel('ä½¿ç”¨ä¸€è‡´æ€§')
        ax2.set_ylabel('éš¸å±¬åº¦')
        ax2.set_title('ä½¿ç”¨ç©©å®šæ€§', fontweight='bold')
        ax2.legend(loc='upper right', fontsize=9)
        ax2.grid(True, alpha=0.3)
        ax2.set_xlim(0, 1)
        ax2.set_ylim(0, 1.1)
        
        # 3. æ™‚é–“åå¥½éš¸å±¬å‡½æ•¸
        ax3 = axes[2]
        x_preference = np.linspace(0, 1, 1000)
        
        if 'time_preference' in self.membership_parameters:
            preference_params = self.membership_parameters['time_preference']
            
            if all(key in preference_params for key in ['p0', 'p25', 'p50', 'p75', 'p100']):
                p0, p25, p50, p75, p100 = [preference_params[k] for k in ['p0', 'p25', 'p50', 'p75', 'p100']]
                
                preference_low = np.array([self.triangular_membership(x, p0, p25, p50) for x in x_preference])
                preference_medium = np.array([self.triangular_membership(x, p25, p50, p75) for x in x_preference])
                preference_high = np.array([self.triangular_membership(x, p50, p75, p100) for x in x_preference])
                
                ax3.plot(x_preference, preference_low, color=colors[0], linewidth=3, 
                        label=f'Low ({p0:.2f}, {p25:.2f}, {p50:.2f})', linestyle=line_styles[0])
                ax3.plot(x_preference, preference_medium, color=colors[1], linewidth=3, 
                        label=f'Medium ({p25:.2f}, {p50:.2f}, {p75:.2f})', linestyle=line_styles[1])
                ax3.plot(x_preference, preference_high, color=colors[2], linewidth=3, 
                        label=f'High ({p50:.2f}, {p75:.2f}, {p100:.2f})', linestyle=line_styles[2])
                
                ax3.fill_between(x_preference, 0, preference_low, alpha=0.2, color=colors[0])
                ax3.fill_between(x_preference, 0, preference_medium, alpha=0.2, color=colors[1])
                ax3.fill_between(x_preference, 0, preference_high, alpha=0.2, color=colors[2])
        
        ax3.set_xlabel('æ™‚é–“åå¥½å¼·åº¦')
        ax3.set_ylabel('éš¸å±¬åº¦')
        ax3.set_title('æ™‚é–“åå¥½', fontweight='bold')
        ax3.legend(loc='upper right', fontsize=9)
        ax3.grid(True, alpha=0.3)
        ax3.set_xlim(0, 1)
        ax3.set_ylim(0, 1.1)
        
        plt.tight_layout()
        plt.show()

    def comprehensive_evaluation(self):
        """å®Œæ•´çš„ç³»çµ±è©•ä¼°"""
        print("\n" + "="*60)
        print("COMPREHENSIVE SYSTEM EVALUATION")
        print("="*60)
        
        # 1. æ•¸æ“šè³ªé‡è©•ä¼°
        print(f"\n1. Data Quality Assessment:")
        print(f"   Quality Score: {self.data_quality_report.get('quality_score', 0):.2f}")
        print(f"   Issues Count: {len(self.data_quality_report.get('issues', []))}")
        
        # 2. çŸ©é™£å®Œæ•´æ€§æª¢æŸ¥
        print(f"\n2. Matrix Completeness:")
        matrices = {
            'Usage Intensity': self.usage_intensity_matrix,
            'Consistency': self.usage_consistency_matrix,
            'Time Preference': self.time_preference_matrix
        }
        
        for name, matrix in matrices.items():
            total_slots = 192
            coverage = len(matrix) / total_slots * 100
            nan_count = 0
            
            for v in matrix.values():
                if isinstance(v, dict):
                    for val in v.values():
                        if isinstance(val, (int, float)) and np.isnan(val):
                            nan_count += 1
                            break
            
            print(f"   {name}: {coverage:.1f}% coverage, {nan_count} entries with NaN")
        
        # 3. ç¿’æ…£åˆ†æ•¸æ¸¬è©¦
        print(f"\n3. Habit Score Tests:")
        test_scenarios = [
            (datetime(2024, 1, 15, 9, 0), (0.4, 0.8), 'å·¥ä½œæ—¥æ—©ä¸Š'),
            (datetime(2024, 1, 15, 14, 30), (0.2, 0.6), 'å·¥ä½œæ—¥ä¸‹åˆ'),
            (datetime(2024, 1, 15, 21, 0), (0.1, 0.5), 'å·¥ä½œæ—¥æ·±å¤œ'),
            (datetime(2024, 1, 13, 10, 15), (0.3, 0.7), 'é€±æœ«ä¸Šåˆ'),
            (datetime(2024, 1, 13, 20, 45), (0.0, 0.3), 'é€±æœ«å‡Œæ™¨'),
        ]
        
        passed_tests = 0
        for test_time, expected_range, desc in test_scenarios:
            try:
                result = self.calculate_habit_score(test_time)
                score = result['habit_score']
                confidence = result['confidence']
                
                is_reasonable = expected_range[0] <= score <= expected_range[1]
                has_confidence = confidence > 0.1
                
                if is_reasonable and has_confidence:
                    passed_tests += 1
                    status = 'âœ“'
                else:
                    status = 'âŒ'
                
                print(f"   {status} {desc}: {score:.3f} (æœŸæœ›: {expected_range})")
            except Exception as e:
                print(f"   âŒ {desc}: Error - {e}")
        
        # 4. ç³»çµ±ç©©å®šæ€§æ¸¬è©¦
        print(f"\n4. System Stability:")
        try:
            base_time = datetime(2024, 1, 15, 14, 0)
            base_result = self.calculate_habit_score(base_time)
            base_score = base_result['habit_score']
            
            sensitivity_diffs = []
            for minutes in [-30, -15, 15, 30]:
                test_time = base_time + timedelta(minutes=minutes)
                result = self.calculate_habit_score(test_time)
                diff = abs(result['habit_score'] - base_score)
                sensitivity_diffs.append(diff)
            
            avg_sensitivity = np.mean(sensitivity_diffs)
            print(f"   Time sensitivity: {avg_sensitivity:.3f}")
            print(f"   Stability: {'Good' if avg_sensitivity < 0.15 else 'Needs improvement'}")
        except Exception as e:
            print(f"   âŒ Stability test failed: {e}")
            avg_sensitivity = 1.0
        
        # 5. æœ€çµ‚è©•åˆ†
        print(f"\n=== FINAL ASSESSMENT ===")
        quality_score = self.data_quality_report.get('quality_score', 0)
        test_pass_rate = passed_tests / len(test_scenarios)
        stability_score = max(0, 1 - avg_sensitivity / 0.2)
        
        overall_score = (quality_score + test_pass_rate + stability_score) / 3
        
        print(f"Data Quality: {quality_score:.2f}")
        print(f"Test Pass Rate: {test_pass_rate:.2f}")
        print(f"Stability Score: {stability_score:.2f}")
        print(f"Overall System Quality: {overall_score:.2f}")
        
        if overall_score >= 0.8:
            print("ğŸ‰ System Quality: Excellent")
        elif overall_score >= 0.6:
            print("âœ… System Quality: Good")
        elif overall_score >= 0.4:
            print("âš ï¸  System Quality: Acceptable")
        else:
            print("âŒ System Quality: Needs Improvement")

    def run_complete_analysis(self, file_path):
        """é‹è¡Œå®Œæ•´åˆ†æ"""
        print("="*80)
        print("IMPROVED USER HABIT SCORE MODULE - COMPLETE ANALYSIS")
        print("="*80)

        # 1. è¼‰å…¥æ•¸æ“š
        df = self.load_data(file_path)
        if df is None:
            print('âŒ Cannot load data')
            return None
        
        # 2. åˆ†æå¼·åº¦è½‰æ›ï¼ˆæ›¿ä»£é–‹é—œæ©Ÿè½‰æ›ï¼‰
        print("\n" + "-"*50)
        self.analyze_intensity_transitions(df)
        
        # 3. è¨ˆç®—ä¸‰å€‹æ ¸å¿ƒæŒ‡æ¨™
        print("\n" + "-"*50)
        self.calculate_usage_intensity(df)
        
        print("\n" + "-"*50)
        self.calculate_usage_consistency(df)
        
        print("\n" + "-"*50)
        self.calculate_time_preference(df)

        # 4. è¨ˆç®—éš¸å±¬åƒæ•¸
        print("\n" + "-"*50)
        self.calculate_membership_parameters()
    
        # 5. å®šç¾©è¦å‰‡
        print("\n" + "-"*50)
        self.define_habit_rules()

        # 6. æ¸¬è©¦è¨ˆç®—
        print("\n" + "-"*50)
        test_results = self.test_habit_score_calculation()

        # 7. ç¶œåˆè©•ä¼°
        print("\n" + "-"*50)
        self.comprehensive_evaluation()

        print("\n" + "-"*50)
        print("==== Plotting Triangular Membership Functions ====")
        self.plot_triangular_membership_functions()

        print("\n" + "="*80)
        print("âœ… ANALYSIS COMPLETE - System ready for production use!")
        print("="*80)

        return {
            'usage_intensity': self.usage_intensity_matrix,
            'consistency': self.usage_consistency_matrix,
            'time_preference': self.time_preference_matrix,
            'membership_parameters': self.membership_parameters,
            'habit_rules': self.habit_rules,
            'test_results': test_results,
            'data_quality': self.data_quality_report
        }

    def test_habit_score_calculation(self, num_tests=5):
        """æ¸¬è©¦ç¿’æ…£åˆ†æ•¸è¨ˆç®—åŠŸèƒ½"""
        print("==== Testing Habit Score Calculation ====")
        
        test_times = [
            datetime(2024, 1, 15, 9, 0),
            datetime(2024, 1, 15, 14, 30),
            datetime(2024, 1, 15, 21, 0),
            datetime(2024, 1, 13, 10, 15),
            datetime(2024, 1, 13, 20, 45),
        ]
        
        test_results = []
        
        for i, test_time in enumerate(test_times[:num_tests]):
            try:
                result = self.calculate_habit_score(test_time)
                
                day_type = "Weekend" if test_time.weekday() >= 5 else "Weekday"
                print(f"\nTest {i+1}: {test_time.strftime('%Y-%m-%d %H:%M')} ({day_type})")
                print(f"  Habit Score: {result['habit_score']:.3f}")
                print(f"  Confidence: {result['confidence']:.3f}")
                print(f"  Valid Rules: {result['valid_rules']}")
                print(f"  Activations - Low: {result['low_activation']:.3f}, "
                      f"Medium: {result['medium_activation']:.3f}, "
                      f"High: {result['high_activation']:.3f}")
                
                test_results.append({
                    'time': test_time,
                    'score': result['habit_score'],
                    'confidence': result['confidence']
                })
                
            except Exception as e:
                print(f"âš ï¸  Error in test {i+1}: {e}")
                test_results.append({
                    'time': test_time,
                    'score': 0.3,
                    'confidence': 0.0
                })
        
        return test_results

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ”§ ç„¡é—œæ©Ÿå ´æ™¯å°ˆç”¨ç”¨æˆ¶ç¿’æ…£åˆ†ææ¨¡çµ„")
    print("="*50)
    
    # åˆå§‹åŒ–å°ˆç”¨æ¨¡çµ„
    no_shutdown_habit_module = NoShutdownUserHabitScoreModule()
    
    # æª”æ¡ˆè·¯å¾‘
    file_path = "C:/Users/ç‹ä¿æ–‡/OneDrive - University of Glasgow/æ–‡ä»¶/glasgow/msc project/data/extended_power_data_2months.csv"
    
    # é‹è¡Œå®Œæ•´åˆ†æ
    result = no_shutdown_habit_module.run_complete_analysis(file_path)
    
    print("\nğŸ¯ ç„¡é—œæ©Ÿå ´æ™¯ç‰¹é»:")
    print("- åŸºæ–¼ä½¿ç”¨å¼·åº¦è½‰æ› (phantom â†” light â†” regular)")
    print("- åˆ†ææ™‚é–“åå¥½æ¨¡å¼è€Œéé–‹é—œæ©Ÿæ¨¡å¼")
    print("- è¨ˆç®—ä½¿ç”¨ä¸€è‡´æ€§è©•ä¼°ç¿’æ…£ç©©å®šæ€§")
    print("- æ›´é©åˆç¾ä»£é›»å­è¨­å‚™çš„å¾…æ©Ÿæ¨¡å¼åˆ†æ")