import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random
from collections import defaultdict

class PowerDataExpander:
    def __init__(self):
        """
        åˆå§‹åŒ–æ•¸æ“šæ“´å±•å™¨
        """
        self.original_data = None
        self.hourly_patterns = {}
        self.weekday_patterns = {}
        self.transition_patterns = {}
        self.missing_patterns = {}
        
    def load_original_data(self, csv_path="C:/Users/ç‹ä¿æ–‡/OneDrive - University of Glasgow/æ–‡ä»¶/glasgow/msc project/data/data_after_preprocessing.csv"):
        """
        è¼‰å…¥é è™•ç†å¾Œçš„CSVæ•¸æ“š
        """
        try:
            self.original_data = pd.read_csv(csv_path)
            self.original_data['timestamp'] = pd.to_datetime(self.original_data['timestamp'])
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.original_data)} ç­†åŸå§‹æ•¸æ“š")
            print(f"ğŸ“… æ™‚é–“ç¯„åœï¼š{self.original_data['timestamp'].min()} åˆ° {self.original_data['timestamp'].max()}")
            return True
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ {csv_path}")
            print("ğŸ’¡ è«‹ç¢ºä¿æ–‡ä»¶åœ¨ç•¶å‰ç›®éŒ„ä¸‹ï¼Œæˆ–æä¾›æ­£ç¢ºçš„æ–‡ä»¶è·¯å¾‘")
            return False
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return False
    
    def analyze_patterns(self):
        """
        åˆ†æåŸå§‹æ•¸æ“šçš„ä½¿ç”¨æ¨¡å¼
        """
        if self.original_data is None:
            raise ValueError("è«‹å…ˆè¼‰å…¥åŸå§‹æ•¸æ“š")
        
        data = self.original_data.copy()
        data['hour'] = data['timestamp'].dt.hour
        data['weekday'] = data['timestamp'].dt.weekday
        data['is_weekend'] = data['weekday'].isin([5, 6])
        data['time_slot'] = data['hour'].apply(self._get_time_slot)
        
        print("ğŸ” é–‹å§‹åˆ†ææ•¸æ“šæ¨¡å¼...")
        
        # 1. åˆ†ææ¯å°æ™‚çš„åŠŸç‡åˆ†ä½ˆ
        self._analyze_hourly_patterns(data)
        
        # 2. åˆ†æå·¥ä½œæ—¥vsé€±æœ«æ¨¡å¼
        self._analyze_weekday_patterns(data)
        
        # 3. åˆ†æç‹€æ…‹è½‰æ›æ¨¡å¼
        self._analyze_transition_patterns(data)
        
        # 4. åˆ†æç¼ºå¤±æ•¸æ“šæ¨¡å¼
        self._analyze_missing_patterns(data)
        
        print("âœ… æ¨¡å¼åˆ†æå®Œæˆ")
    
    def _analyze_hourly_patterns(self, data):
        """
        åˆ†ææ¯å°æ™‚çš„ä½¿ç”¨æ¨¡å¼
        """
        for hour in range(24):
            hour_data = data[data['hour'] == hour]
            if len(hour_data) > 0:
                self.hourly_patterns[hour] = {
                    'power_mean': hour_data['power'].mean(),
                    'power_std': hour_data['power'].std(),
                    'power_min': hour_data['power'].min(),
                    'power_max': hour_data['power'].max(),
                    'phantom_prob': hour_data['is_phantom_load'].mean(),
                    'light_prob': hour_data['is_light_use'].mean(),
                    'regular_prob': hour_data['is_regular_use'].mean(),
                    'count': len(hour_data)
                }
        
        print(f"ğŸ“Š åˆ†æäº† {len(self.hourly_patterns)} å€‹å°æ™‚çš„æ¨¡å¼")
    
    def _analyze_weekday_patterns(self, data):
        """
        åˆ†æå·¥ä½œæ—¥vsé€±æœ«æ¨¡å¼
        """
        for is_weekend in [False, True]:
            weekend_data = data[data['is_weekend'] == is_weekend]
            day_type = "é€±æœ«" if is_weekend else "å·¥ä½œæ—¥"
            
            if len(weekend_data) > 0:
                self.weekday_patterns[is_weekend] = {
                    'power_mean': weekend_data['power'].mean(),
                    'power_std': weekend_data['power'].std(),
                    'phantom_prob': weekend_data['is_phantom_load'].mean(),
                    'light_prob': weekend_data['is_light_use'].mean(),
                    'regular_prob': weekend_data['is_regular_use'].mean(),
                    'count': len(weekend_data)
                }
                print(f"ğŸ“ˆ {day_type}ï¼šå¹³å‡åŠŸç‡ {weekend_data['power'].mean():.1f}W")
    
    def _analyze_transition_patterns(self, data):
        """
        åˆ†æç‹€æ…‹è½‰æ›æ¨¡å¼
        """
        data_sorted = data.sort_values('timestamp')
        data_sorted['prev_state'] = data_sorted['power_state'].shift(1)
        
        transitions = data_sorted.groupby(['prev_state', 'power_state']).size()
        total_transitions = len(data_sorted) - 1
        
        for (prev_state, curr_state), count in transitions.items():
            if pd.notna(prev_state):
                key = f"{prev_state}â†’{curr_state}"
                self.transition_patterns[key] = {
                    'probability': count / total_transitions,
                    'count': count
                }
        
        print(f"ğŸ”„ åˆ†æäº† {len(self.transition_patterns)} ç¨®ç‹€æ…‹è½‰æ›")
    
    def _analyze_missing_patterns(self, data):
        """
        åˆ†æç¼ºå¤±æ•¸æ“šæ¨¡å¼ï¼ˆåŸºæ–¼æ™‚é–“å·®ç•°ï¼‰
        """
        # åˆ†ææ™‚é–“é–“éš”ï¼Œè­˜åˆ¥å¯èƒ½çš„ç¼ºå¤±æ¨¡å¼
        data_sorted = data.sort_values('timestamp')
        
        # æ‰¾å‡ºéæ¨™æº–é–“éš”ï¼ˆä¸æ˜¯900ç§’çš„ï¼‰
        non_standard = data_sorted[data_sorted['time_diff_seconds'] > 900]
        
        for hour in range(24):
            hour_missing = non_standard[non_standard['hour'] == hour]
            missing_prob = len(hour_missing) / max(1, len(data_sorted[data_sorted['hour'] == hour]))
            self.missing_patterns[hour] = min(0.15, missing_prob)  # é™åˆ¶æœ€å¤§ç¼ºå¤±ç‡15%
        
        print(f"ğŸ“‰ åˆ†æäº†å„æ™‚æ®µçš„æ•¸æ“šç¼ºå¤±æ¨¡å¼")
    
    def _get_time_slot(self, hour):
        """
        å°‡å°æ™‚è½‰æ›ç‚ºæ™‚æ®µ
        """
        if 6 <= hour <= 9:
            return "morning"
        elif 10 <= hour <= 17:
            return "daytime"
        elif 18 <= hour <= 22:
            return "evening"
        else:
            return "night"
    
    def generate_extended_data(self, weeks=8):
        """
        ç”Ÿæˆæ“´å±•æ•¸æ“šï¼ˆ2å€‹æœˆï¼‰
        """
        if not self.hourly_patterns:
            self.analyze_patterns()
        
        # ç¢ºå®šæ–°çš„æ™‚é–“ç¯„åœ
        original_start = self.original_data['timestamp'].min()
        new_start = original_start
        new_end = new_start + timedelta(weeks=weeks)
        
        # ç”Ÿæˆ15åˆ†é˜é–“éš”çš„æ™‚é–“åºåˆ—
        time_range = pd.date_range(start=new_start, end=new_end, freq='15min')
        
        print(f"ğŸš€ é–‹å§‹ç”Ÿæˆ {weeks} é€±çš„æ“´å±•æ•¸æ“š...")
        print(f"ğŸ“… æ™‚é–“ç¯„åœï¼š{new_start.date()} åˆ° {new_end.date()}")
        print(f"ğŸ“ é è¨ˆç”Ÿæˆï¼š{len(time_range):,} ç­†è¨˜éŒ„")
        
        extended_records = []
        prev_power_state = "phantom load"  # åˆå§‹ç‹€æ…‹
        
        for i, timestamp in enumerate(time_range):
            # è¨ˆç®—æ™‚é–“å·®
            if i == 0:
                time_diff = None
            else:
                time_diff = 900.0  # 15åˆ†é˜ = 900ç§’
            
            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²æ¨¡æ“¬ç¼ºå¤±æ•¸æ“š
            if self._should_skip_record(timestamp):
                if i > 0:
                    # æ›´æ–°ä¸Šä¸€ç­†è¨˜éŒ„çš„æ™‚é–“å·®
                    extended_records[-1]['time_diff_seconds'] = extended_records[-1].get('time_diff_seconds', 0) + 900
                continue
            
            # ç”ŸæˆåŠŸç‡å’Œç‹€æ…‹
            power, power_state = self._generate_power_and_state(timestamp, prev_power_state)
            prev_power_state = power_state
            
            # å‰µå»ºè¨˜éŒ„
            record = {
                'timestamp': timestamp,
                'power': power,
                'power_state': power_state,
                'is_phantom_load': power_state == 'phantom load',
                'is_off': False,  # æ ¹æ“šæ‚¨çš„æ•¸æ“šï¼Œæ²’æœ‰å®Œå…¨é—œæ©Ÿ
                'is_on': True,
                'is_light_use': power_state == 'light use',
                'is_regular_use': power_state == 'regular use',
                'time_diff_seconds': time_diff
            }
            
            extended_records.append(record)
        
        # è½‰æ›ç‚ºDataFrame
        extended_df = pd.DataFrame(extended_records)
        
        print(f"âœ… ç”Ÿæˆå®Œæˆï¼š{len(extended_df):,} ç­†è¨˜éŒ„")
        print(f"ğŸ“‰ æ¨¡æ“¬ç¼ºå¤±ï¼š{len(time_range) - len(extended_df):,} ç­†")
        
        return extended_df
    
    def _should_skip_record(self, timestamp):
        """
        æ ¹æ“šå­¸ç¿’åˆ°çš„ç¼ºå¤±æ¨¡å¼æ±ºå®šæ˜¯å¦è·³éè¨˜éŒ„
        """
        hour = timestamp.hour
        missing_prob = self.missing_patterns.get(hour, 0.02)
        
        # æ·»åŠ ä¸€äº›éš¨æ©Ÿæ€§
        return np.random.random() < missing_prob
    
    def _generate_power_and_state(self, timestamp, prev_state):
        """
        åŸºæ–¼æ™‚é–“å’Œå‰ä¸€ç‹€æ…‹ç”ŸæˆåŠŸç‡å€¼å’Œç‹€æ…‹
        """
        hour = timestamp.hour
        weekday = timestamp.weekday()
        is_weekend = weekday >= 5
        
        # ç²å–è©²å°æ™‚çš„åŸºç¤æ¨¡å¼
        if hour in self.hourly_patterns:
            hour_pattern = self.hourly_patterns[hour]
        else:
            # ä½¿ç”¨å…¨å¤©å¹³å‡ä½œç‚ºå¾Œå‚™
            hour_pattern = {
                'power_mean': self.original_data['power'].mean(),
                'power_std': self.original_data['power'].std(),
                'phantom_prob': 0.76,  # åŸºæ–¼æ‚¨çš„çµ±è¨ˆ
                'light_prob': 0.20,
                'regular_prob': 0.04
            }
        
        # é€±æœ«èª¿æ•´å› å­
        weekend_factor = 1.0
        if is_weekend:
            weekend_factor = self.weekday_patterns.get(True, {}).get('power_mean', 1) / \
                           self.weekday_patterns.get(False, {}).get('power_mean', 1)
        
        # ç‹€æ…‹è½‰æ›è€ƒæ…®
        state_probs = self._get_state_probabilities(hour_pattern, prev_state)
        
        # éš¨æ©Ÿé¸æ“‡ç‹€æ…‹
        rand = np.random.random()
        if rand < state_probs['phantom']:
            power_state = 'phantom load'
            power = np.random.normal(18, 2)  # åŸºæ–¼æ‚¨çš„æ•¸æ“š
            power = np.clip(power, 16, 35)
        elif rand < state_probs['phantom'] + state_probs['light']:
            power_state = 'light use'
            power = np.random.normal(55, 10)
            power = np.clip(power, 37, 75)
        else:
            power_state = 'regular use'
            power = np.random.normal(90, 20)
            power = np.clip(power, 80, 173)
        
        # æ‡‰ç”¨é€±æœ«å› å­å’Œæ·»åŠ è®Šç•°
        power *= weekend_factor
        power *= np.random.normal(1.0, 0.05)  # 5%çš„éš¨æ©Ÿè®Šç•°
        
        # ç¢ºä¿åŠŸç‡å€¼åœ¨åˆç†ç¯„åœå…§
        power = round(max(16, min(173, power)), 1)
        
        return power, power_state
    
    def _get_state_probabilities(self, hour_pattern, prev_state):
        """
        åŸºæ–¼å°æ™‚æ¨¡å¼å’Œå‰ä¸€ç‹€æ…‹è¨ˆç®—ç‹€æ…‹æ¦‚ç‡
        """
        base_probs = {
            'phantom': hour_pattern.get('phantom_prob', 0.76),
            'light': hour_pattern.get('light_prob', 0.20),
            'regular': hour_pattern.get('regular_prob', 0.04)
        }
        
        # ç‹€æ…‹æŒçºŒæ€§èª¿æ•´ï¼ˆç‹€æ…‹æœ‰ä¸€å®šæ…£æ€§ï¼‰
        persistence_factor = 0.3
        if prev_state in ['phantom load', 'phantom']:
            base_probs['phantom'] += persistence_factor * (1 - base_probs['phantom'])
        elif prev_state in ['light use', 'light']:
            base_probs['light'] += persistence_factor * (1 - base_probs['light'])
        elif prev_state in ['regular use', 'regular']:
            base_probs['regular'] += persistence_factor * (1 - base_probs['regular'])
        
        # æ­¸ä¸€åŒ–
        total = sum(base_probs.values())
        return {k: v/total for k, v in base_probs.items()}
    
    def save_extended_data(self, extended_df, filename="extended_power_data_2months.csv"):
        """
        ä¿å­˜æ“´å±•æ•¸æ“šä¸¦é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        """
        extended_df.to_csv(filename, index=False)
        print(f"\nğŸ’¾ æ“´å±•æ•¸æ“šå·²ä¿å­˜åˆ°ï¼š{filename}")
        
        # é¡¯ç¤ºè©³ç´°çµ±è¨ˆ
        self._print_comprehensive_statistics(extended_df)
        
        return filename
    
    def _print_comprehensive_statistics(self, df):
        """
        é¡¯ç¤ºcomprehensiveçµ±è¨ˆä¿¡æ¯
        """
        print("\n" + "="*80)
        print("ğŸ“Š æ“´å±•æ•¸æ“šçµ±è¨ˆå ±å‘Š")
        print("="*80)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“… æ™‚é–“ç¯„åœï¼š{df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
        print(f"ğŸ“ ç¸½è¨˜éŒ„æ•¸ï¼š{len(df):,}")
        print(f"â±ï¸  æ™‚é–“è·¨åº¦ï¼š{(df['timestamp'].max() - df['timestamp'].min()).days} å¤©")
        
        # åŠŸç‡çµ±è¨ˆ
        print(f"\nâš¡ åŠŸç‡çµ±è¨ˆï¼š")
        print(f"   å¹³å‡åŠŸç‡ï¼š{df['power'].mean():.1f}W")
        print(f"   æœ€å°åŠŸç‡ï¼š{df['power'].min():.1f}W")
        print(f"   æœ€å¤§åŠŸç‡ï¼š{df['power'].max():.1f}W")
        print(f"   æ¨™æº–å·®ï¼š{df['power'].std():.1f}W")
        
        # ç‹€æ…‹åˆ†ä½ˆ
        print(f"\nğŸ”‹ ä½¿ç”¨ç‹€æ…‹åˆ†ä½ˆï¼š")
        state_counts = df['power_state'].value_counts()
        for state, count in state_counts.items():
            percentage = count / len(df) * 100
            print(f"   {state}: {count:,} ç­† ({percentage:.1f}%)")
        
        # æ™‚é–“åˆ†ä½ˆ
        print(f"\nğŸ“… æ™‚é–“åˆ†ä½ˆï¼š")
        df_copy = df.copy()
        df_copy['weekday'] = df_copy['timestamp'].dt.weekday
        weekday_count = (df_copy['weekday'] < 5).sum()
        weekend_count = (df_copy['weekday'] >= 5).sum()
        print(f"   å·¥ä½œæ—¥ï¼š{weekday_count:,} ç­† ({weekday_count/len(df)*100:.1f}%)")
        print(f"   é€±æœ«ï¼š{weekend_count:,} ç­† ({weekend_count/len(df)*100:.1f}%)")
        
        # é ä¼°è€—é›»é‡
        print(f"\nğŸ’¡ é ä¼°è€—é›»é‡ï¼š")
        total_kwh = df['power'].sum() * 0.25 / 1000  # 15åˆ†é˜é–“éš”
        daily_kwh = total_kwh / ((df['timestamp'].max() - df['timestamp'].min()).days)
        annual_kwh = daily_kwh * 365
        print(f"   ç¸½è€—é›»é‡ï¼š{total_kwh:.2f} kWh")
        print(f"   æ—¥å‡è€—é›»ï¼š{daily_kwh:.2f} kWh")
        print(f"   å¹´åº¦é ä¼°ï¼š{annual_kwh:.0f} kWh")
        
        # å°æ¯”åŸå§‹æ•¸æ“š
        if hasattr(self, 'original_data') and self.original_data is not None:
            orig_mean = self.original_data['power'].mean()
            orig_phantom_rate = self.original_data['is_phantom_load'].mean()
            new_phantom_rate = df['is_phantom_load'].mean()
            
            print(f"\nğŸ”„ èˆ‡åŸå§‹æ•¸æ“šå°æ¯”ï¼š")
            print(f"   åŸå§‹å¹³å‡åŠŸç‡ï¼š{orig_mean:.1f}W â†’ æ“´å±•å¹³å‡åŠŸç‡ï¼š{df['power'].mean():.1f}W")
            print(f"   åŸå§‹Phantom Loadç‡ï¼š{orig_phantom_rate:.1%} â†’ æ“´å±•Phantom Loadç‡ï¼š{new_phantom_rate:.1%}")
        
        print("="*80)

# ä½¿ç”¨ç¤ºä¾‹
def main():
    """
    ä¸»å‡½æ•¸ - å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ•¸æ“šæ“´å±•å™¨
    """
    print("ğŸš€ é›»åŠ›æ•¸æ“šæ“´å±•å™¨å•Ÿå‹•")
    print("="*50)
    
    # åˆå§‹åŒ–æ“´å±•å™¨
    expander = PowerDataExpander()
    
    # è¼‰å…¥æ•¸æ“š
    if not expander.load_original_data("data_after_preprocessing.csv"):
        print("âŒ ç„¡æ³•è¼‰å…¥æ•¸æ“šï¼Œè«‹æª¢æŸ¥æ–‡ä»¶è·¯å¾‘")
        return
    
    # åˆ†ææ¨¡å¼
    expander.analyze_patterns()
    
    # ç”Ÿæˆ8é€±ï¼ˆ2å€‹æœˆï¼‰çš„æ“´å±•æ•¸æ“š
    extended_data = expander.generate_extended_data(weeks=8)
    
    # ä¿å­˜æ•¸æ“š
    filename = expander.save_extended_data(extended_data)
    
    print(f"\nğŸ‰ æ“´å±•å®Œæˆï¼è«‹æŸ¥çœ‹ {filename}")
    print("ğŸ’¡ æ‚¨ç¾åœ¨å¯ä»¥ä½¿ç”¨é€™å€‹æ“´å±•æ•¸æ“šé›†ä¾†è¨“ç·´æ‚¨çš„æ™ºèƒ½é›»æºç®¡ç†ç³»çµ±")

if __name__ == "__main__":
    main()